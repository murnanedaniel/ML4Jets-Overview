{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Data Needed for ML4Jets Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cds(params):\n",
    "    \"\"\"\n",
    "    Search CERN Document Server (CDS) with raw query parameters\n",
    "    \"\"\"\n",
    "    base_url = \"https://cds.cern.ch/search\"\n",
    "    \n",
    "    # Ensure we get JSON output if not specified\n",
    "    if 'of' not in params:\n",
    "        params['of'] = 'recjson'\n",
    "    \n",
    "    try:\n",
    "        # Make request with raw params\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Try to parse just the array part\n",
    "        text = response.text.strip()\n",
    "        if text.startswith('['):\n",
    "            # Replace concatenated arrays with comma-separated entries\n",
    "            text = text.replace('}][{', '},{')\n",
    "            \n",
    "            try:\n",
    "                return json.loads(text)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON: {e}\")\n",
    "                return None\n",
    "                \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making request: {e}\")\n",
    "        return None\n",
    "\n",
    "def filter_recent_records(records, max_age_days=365):\n",
    "    \"\"\"\n",
    "    Filter records to keep only those newer than max_age_days\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    records : list\n",
    "        List of CDS records\n",
    "    max_age_days : int\n",
    "        Maximum age in days\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Filtered list of records\n",
    "    \"\"\"\n",
    "    current_date = datetime.now()\n",
    "    cutoff_date = current_date - timedelta(days=max_age_days)\n",
    "    \n",
    "    filtered_records = []\n",
    "    for record in records:\n",
    "        # Try to get creation date from different possible fields\n",
    "        date_str = (record.get('creation_date') or \n",
    "                   record.get('imprint', {}).get('date') or \n",
    "                   record.get('prepublication', {}).get('date'))\n",
    "        \n",
    "        if date_str:\n",
    "            try:\n",
    "                # Handle different date formats\n",
    "                if 'T' in date_str:  # ISO format like '2024-11-01T09:06:20'\n",
    "                    record_date = datetime.fromisoformat(date_str)\n",
    "                elif len(date_str) == 4:  # Just year\n",
    "                    record_date = datetime.strptime(date_str, '%Y')\n",
    "                else:  # Try common format 'DD Mon YYYY'\n",
    "                    record_date = datetime.strptime(date_str, '%d %b %Y')\n",
    "                \n",
    "                if record_date >= cutoff_date:\n",
    "                    filtered_records.append(record)\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: Could not parse date {date_str}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return filtered_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATLAS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'p1': 'machine learning',\n",
    "    'f1': 'abstract',\n",
    "    'rg': 100,\n",
    "    'c': ['ATLAS Conference Notes', 'ATLAS Conference Slides', 'ATLAS PUB Notes', 'ATLAS Preprints']\n",
    "}\n",
    "results = search_cds(\n",
    "        params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_results = filter_recent_records(results)\n",
    "len(recent_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: An implementation of Neural Simulation-Based Inference for Parameter Estimation in ATLAS\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Neural Simulation-Based Inference (NSBI) is a powerful class of machine learning (ML)-based methods for statistical inference that naturally handles high-dimensional parameter estimation without the need to bin data into low-dimensional summary histograms. Such methods are promising for a range of measurements, including at the Large Hadron Collider (LHC), where no single observable may be optimal to scan over the entire theoretical phase space under consideration, or where binning data into histograms could result in a loss of sensitivity. This work develops an NSBI framework for statistical inference, using neural networks to estimate probability density ratios, which enables the application of NSBI to a full-scale LHC analysis. It incorporates a large number of systematic uncertainties, quantifies the uncertainty coming from finite training statistics, develops a method to construct confidence intervals, and demonstrates a series of intermediate diagnostic checks that can be performed to validate the robustness of the method. As an example, the power and feasibility of the method are demonstrated on simulated data for a simplified version of an off-shell Higgs boson couplings measurement in the four-leptons final states. This NSBI framework is an extension of the standard statistical framework used by LHC experiments and can benefit a large number of physics analyses.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Measurement of Track Functions in ATLAS Run 2 Data\n",
      "Date: 30 Jul 2024\n",
      "Abstract: {'summary': \"Measurements of jet substructure are key to probing the energy frontier at colliders, and many of them use track-based observables which take advantage of the angular precision of tracking detectors. Theoretical calculations of track-based observables require ``track functions'', which characterize the transverse momentum fraction $r_q$ carried by charged hadrons from a fragmenting quark or gluon. This letter presents a direct measurement of $r_q$ distributions in dijet events from the $140$ fb$^{-1}$ of $\\\\sqrt{s}~=~13$ TeV proton-proton collisions collected by the ATLAS detector. The first six moments of the $r_q$ distribution are extracted and demixed based on theory predictions to present values for quark and gluon jets separately. The data are corrected for detector effects based on machine-learning methods. The scale evolution of the moments of the $r_q$ distribution provides direct access to non-linear renormalization group evolution equations of QCD, and is compared with analytic predictions. When incorporated into future theoretical calculations, these results will enable a precision program of theory-data comparison for track-based jet substructure observables.\"}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Recent Advances in the GAN-based Fast Calorimeter Simulation of the ATLAS Experiment\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Simulation of the detector response is a major computational challenge in modern High-Energy Physics experiments, accounting for about 40% of the total computational resources used in ATLAS. The simulation of the calorimeter response is particularly demanding, consuming about 80% of the total simulation time. In order to make the best use of the available computational resources, fast simulation tools based on Machine Learning techniques have been developed to simulate the calorimeter response faster than Geant4 while maintaining a high level of accuracy. One such tool, developed by the ATLAS Collaboration and currently in production for LHC Run 3, is FastCaloGAN, which uses Generative Adversarial Networks (GANs) to generate electromagnetic and hadronic showers. To facilitate the training and optimisation of the GANs, and to enable a more efficient use of computational resources, a container-based system, FastCaloGANtainer, facilitates the deployment of the FastCaloGAN training on complementary high-performance resources such as High Performance Computing (HPC) farms and ensures its operational independence from the underlying system. This talk presents the latest developments in FastCaloGAN and FastCaloGANtainer, discussing their technical details and recent improvements in terms of Physics and computational performance. For FastCaloGAN, these improvements include an improved voxelisation and extension to further use cases (e.g. particle types not yet covered), while for FastCaloGANtainer they concern its deployment on a wider variety of resources with multi-CPU/GPU nodes and different architectures (including cutting-edge HPC clusters such as Leonardo at CINECA in Bologna, Italy).'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Parameter Estimation in ATLAS with Neural Simulation-Based Inference\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Neural Simulation-Based Inference (NSBI) is a powerful class of machine learning (ML)-based methods for statistical inference that naturally handle high dimensional parameter estimation without the need to bin data into low-dimensional summary histograms. Such methods are promising for a range of measurements at the Large Hadron Collider, where no single observable may be optimal to scan over the entire theoretical phase space under consideration, or where binning data into histograms could result in a loss of sensitivity. This work develops an NSBI framework that, for the first time, allows NSBI to be applied to a full-scale LHC analysis, by successfully incorporating a large number of systematic uncertainties, quantifying the uncertainty coming from finite training statistics, developing a method to construct confidence intervals, and demonstrating a series of intermediate diagnostic checks that can be performed to validate the robustness of the method. As an example, the power and feasibility of the method are demonstrated for an off-shell Higgs boson couplings measurement in the four lepton decay channel, using simulated samples. The proposed method is a generalisation of the standard statistical framework at the LHC, and can benefit a large number of physics analyses. This work serves as a blueprint for measurements at the LHC using NSBI.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Towards Machine-Learning Particle Flow with the ATLAS Detector at the LHC\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Particle flow reconstruction at colliders combines various detector subsystems (typically the calorimeter and tracker) to provide a combined event interpretation that utilizes the strength of each detector. The accurate association of redundant measurements of the same particle between detectors is the key challenge in this technique. This contribution describes recent progress in the ATLAS experiment towards utilizing machine-learning to improve particle flow in the ATLAS detector. In particular, point-cloud techniques are utilized to associate measurements from the same particle, leading to reduced confusion compared to baseline techniques. Next steps towards further testing and implementation will be discussed.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Improving Computational Performance of ATLAS GNN Track Reconstruction Pipeline\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Track reconstruction is an essential element of modern and future collider experiments, including the ATLAS detector. The HL-LHC upgrade of the ATLAS detector brings an unprecedented tracking reconstruction challenge, both in terms of the large number of silicon hit cluster readouts and the throughput required for budget-constrained track reconstruction. Traditional track reconstruction techniques often contain steps that scale combinatorically, which could be ameliorated with deep learning approaches. The GNN4ITk project has been shown to apply geometric deep learning algorithms for tracking to a similar level of physics performance with traditional techniques while scaling sub-quadratically. In this contribution, we compare the computational performance of a variety of pipeline configurations and machine learning inference methods. These include heuristic-and-ML-based graph segmentation techniques, GPU-based module map graph construction, and studies of high throughput graph convolutional kernels. In this contribution, we present benchmarks of latency, throughput, memory usage, and power consumption of each pipeline configuration.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: ATLAS EFT Results in the Top Quark Sector\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'The overview summarises the latest Effective Field Theory (EFT) analyses conducted by the ATLAS experiment, focusing on latest results in constraining physics beyond the Standard Model using precision measurements. Emphasis is placed on the top quark sector, where EFT provides a powerful framework for interpreting deviations in top quark production and decay processes. We highlight three of the most recent results: constraints on EFT operators from ttgamma production, charged lepton flavour violation, and single top production in t-channel. These analyses employ advanced statistical techniques, machine learning methods, and state-of-the-art Monte Carlo simulations to achieve optimal sensitivity to potential new physics effects.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond\n",
      "Date: 25 Oct 2024\n",
      "Abstract: {'summary': 'As we are approaching the high-luminosity era of the LHC, the computational requirements of the ATLAS experiment are expected to increase significantly in the coming years. In particular, the simulation of MC events is immensely computationally demanding, and their limited availability is one of the major sources of systematic uncertainties in many physics analyses. The main bottleneck in the detector simulation is the detailed simulation of electromagnetic and hadronic showers in the ATLAS calorimeter system using Geant4. In order to increase the MC statistics and to leverage the available CPU resources for LHC Run 3, the ATLAS collaboration has recently put into production a refined and significantly improved version of its state-of-the-art fast simulation tool AtlFast3. AtlFast3 uses classical parametric and machine learning based approaches such as Generative Adversarial Networks (GANs) for the fast simulation of LHC events in the ATLAS detector. This talk will present the newly improved version of AtlFast3 that is currently in production for the simulation of Run 3 samples. In addition, ideas and plans for the future of fast simulation in ATLAS will also be discussed.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Boosted Higgs decays to b-quarks in ATLAS\n",
      "Date: 25 Sep 2024\n",
      "Abstract: {'summary': 'The Higgs boson, central to the Standard model, is a powerful probe for new physics theories. Precise measurements of the Higgs coupling to the third generation particles could reveal deviations from the Standard Model predictions, potentially leading to the discovery of new physics processes, especially at high energy. Investigating the Higgs decaying into a pair of b-quarks is advantageous due to the high branching ratio which provides a large dataset, facilitating the investigation of the boosted regime at high pT, above 400 GeV. This talk will present recent results from the ATLAS collaboration of the Higgs boson decays to b-quarks analysis with an emphasis on machine learning techniques, crucial to enhance the precision of high pT measurements.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Performance versus uncertainty in boosted top tagging with the ATLAS detector\n",
      "Date: 10 Sep 2024\n",
      "Abstract: {'summary': 'The identification of top quark decays, known as top tagging, is a crucial component in many measurements and searches at the Large Hadron Collider (LHC). Recently machine learning techniques have greatly improved the performance of top tagging algorithms. This poster presents the performance of several machine learning based jet tagging methods. In particular the performance of a Lund jet plane based tagger is compared to existing baselines. Then the systematic uncertainties in network performance are estimated through an approximate procedure that allows the size of the produced uncertainties to be quantified along with the raw performance. The most performant algorithms are found to produce the largest uncertainties, motivating the development of methods to reduce these uncertainties without compromising performance.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Flavour Tagging with Graph Neural Network with the ATLAS Detector\n",
      "Date: 10 Sep 2024\n",
      "Abstract: {'summary': 'Flavour-tagging is a critical component of the ATLAS experiment physics programme. Existing flavour tagging algorithms rely on several low-level taggers, which are a combination of physically informed algorithms and machine learning models. A novel approach presented here instead uses a single machine learning model based on reconstructed tracks, avoiding the need for low-level taggers based on secondary vertexing algorithms. This new approach reduces complexity and improves tagging performance. This model employs a transformer architecture to process information from a variable number of tracks and other objects in the jet in order to simultaneously predict the jets flavour, the partitioning of tracks into vertices, and the physical origin of each track. The inclusion of auxiliary tasks aids the models interpretability. The new approach significantly improves jet flavour identification performance compared to existing methods in both Monte-Carlo simulation and collision data. Notably, the versatility of the approach is demonstrated by its successful application in boosted Higgs tagging using large-R jets.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: ATLAS searches for electroweak supersymmetry with compressed spectra\n",
      "Date: 03 Sep 2024\n",
      "Abstract: {'summary': 'Supersymmetry (SUSY) models with featuring small mass splittings between one or more particles and the lightest neutralino could solve the hierarchy problem as well as offer a suitable dark matter candidate consistent with the observed thermal-relic dark matter density. However, the detection of SUSY higgsinos at the LHC remains challenging especially if their mass-splitting is O(1 GeV) or lower. Searches are developed using 140 fb^{-1} of proton-proton collision data collected by the ATLAS Detector at a center-of-mass energy \\\\sqrt{s}=13 TeV to overcome the challenge. Novel techniques are developed exploiting machine-learning techniques, low-momentum tracks with large transverse impact parameters, or topologies consistent with VBF production of the supersymmetric particles. Results are interpreted in terms of SUSY simplified models and, for the first time since the LEP era, several gaps in different ranges of mass-splittings are excluded.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Flavour Tagging with Graph Neural Network at ATLAS\n",
      "Date: 12 Aug 2024\n",
      "Abstract: {'summary': 'Flavour-tagging is a critical component of the ATLAS experiment physics programme. Existing flavour tagging algorithms rely on several low-level taggers, which are a combination of physically informed algorithms and machine learning models. A novel approach presented here instead uses a single machine learning model based on reconstructed tracks, avoiding the need for low-level taggers based on secondary vertexing algorithms. This new approach reduces complexity and improves tagging performance. This model employs a transformer architecture to process information from a variable number of tracks and other objects in the jet in order to simultaneously predict the jets flavour, the partitioning of tracks into vertices, and the physical origin of each track. The new approach significantly improves jet flavour identification performance compared to existing methods in both Monte-Carlo simulation and collision data.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Classifying hadronic objects in ATLAS with ML/AI algorithms\n",
      "Date: 12 Aug 2024\n",
      "Abstract: {'summary': 'Hadronic object reconstruction is one of the most promising settings for cutting-edge machine learning and artificial intelligence algorithms at the LHC. In this contribution, highlights of ML/AI applications by ATLAS to particle and boosted-object identification, MET reconstruction and other tasks will be presented.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Searches for new physics using unsupervised machine learning for anomaly detection in $\\sqrt{s}$ = 13 TeV $pp$ collisions recorded by the ATLAS detector at the LHC\n",
      "Date: 09 Aug 2024\n",
      "Abstract: {'summary': 'Various searches for new resonances using unsupervised machine learning for anomaly detection are presented. These searches look at two-body invariant masses including leptons, at a heavy resonance Y decaying into a Standard Model Higgs boson H and a new particle X in a fully hadronic final state, or at the masses of two jets.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Classifying hadronic objects in ATLAS with ML/AI algorithms\n",
      "Date: 09 Aug 2024\n",
      "Abstract: {'summary': 'Hadronic object reconstruction is one of the most promising settings for cutting-edge machine learning and artificial intelligence algorithms at the LHC. In this contribution, highlights of ML/AI applications by ATLAS to particle and boosted-object identification, MET reconstruction and other tasks will be presented.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: New ATLAS $t\\bar{t}H(b\\bar{b})$ Run 2 Analysis\n",
      "Date: 05 Aug 2024\n",
      "Abstract: {'summary': 'The associated production of the Higgs boson with the top quark allows to directly probe the Top Yukawa coupling, which is a key parameter for the Standard Model. The presented ttH(bb) analysis exploits the distinctive signature of the large H-> bb branching ratio and the leptonic decays of the top quarks and, uses the full Run 2 dataset collected with the ATLAS detector at the centre-of-mass energy of 13 TeV. Improved reconstruction and machine learning techniques are deployed to optimise the signal-background separation. Differential measurements are explored within the STXS formalism, as a function of the Higgs boson transverse momentum. The results are compared with the predictions of the Standard Model.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: The Fast Simulation Program of ATLAS at the LHC\n",
      "Date: 22 Jul 2024\n",
      "Abstract: {'summary': 'The simulation of Monte Carlo (MC) events is a crucial task and an indispensable ingredient for every physics analysis. Geant4 is the state-of-the-art tool used for detailed simulations of the ATLAS detector, which however requires large CPU resources. To reduce the CPU needs, which in turn enables the production of higher statistics MC samples, ATLAS has developed a strong program to replace parts of the simulation chain by fast simulation tools. These developments pave the way towards High Luminosity LHC when resources will be even scarcer.\\u2028Among those tools is AtlFast3, which utilizes a combination of Generative Adversarial Networks (GANs) and sophisticated parametrizations for the fast simulation of showers in the electromagnetic and hadronic calorimeters. For the Run 3 MC campaign, various improvements of AtlFast3 were developed, for example a refinement and extended usage of the GANs and a better model of the punch through of showers into the muon system. Consequently, the performance of AtlFast3 in Run 3 is better than ever. ATLAS also aspires to use fast simulation in the inner detector. FATRAS is a tool that approximates particle interactions with the material through physics formalisms. An integration of FATRAS with the experiment-independent common tracking software (ACTS) is also in development.\\u2028Track overlay is a technique to speed-up the production of MC samples that include additional interactions (pile-up) aside the hard-scatter interaction. The idea is to reconstruct pile-up tracks before they are merged with the hard-scatter, which reduces CPU needs. Machine learning techniques are used to ensure this method can even be applied in dense tracking environments. This talk will discuss the status of the development of these tools as well as their performance in terms of physics modeling and computing resources.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Enhancing Prompt Lepton Identification: Development and Optimization of the PLIT Tagger\n",
      "Date: 19 Jul 2024\n",
      "Abstract: {'summary': \"Within the ATLAS Experiment the Prompt Lepton Isolation Tagger (PLIT) served as an essential tool to distinguish between prompt muons originating from the decays of W and Z bosons and non-prompt muons generated in the semi-leptonic decays of b- and c-hadrons. Its central role was to effectively mitigate the presence of fake and non-prompt leptons in various multi-lepton final state analyses and had been extensively used in Run-2. The poster will present the ongoing efforts in developing and optimizing this tagger for Run-3 data analyses. Through the integration of new features and the exploration of novel machine learning algorithms, the tagger's discrimination power can be enhanced, allowing for more precise identification of prompt leptons originating from electroweak boson decays.\"}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Searches for new phenomena using Anomaly Detection at the ATLAS experiment\n",
      "Date: 19 Jul 2024\n",
      "Abstract: {'summary': 'After the discovery of the Higgs boson at the Large Hadron Collider (LHC) at CERN, we undoubtedly live in a phase characterized by a lack of discoveries of Beyond Standard Model physics in particles accelerators. Anomaly Detection is a novel machine learning approach that could be used to resolve this stalemate, as it allows to be very general with the searched signatures without losing sensibility to possible signals. ATLAS analyses are taking the first steps in this direction, following the results obtained from CWoLa (Classification Without Labels) based resonant searches. The poster shows the results obtained with Anomaly Detections approaches in ATLAS, where events are selected solely because of their incompatibility with a learned background-only model. In particular, my focus is on the search for a heavy resonance Y decaying into a Standard Model Higgs boson H and a new particle X in a fully hadronic final state, which represents the first application of fully unsupervised machine learning to an ATLAS analysis.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Recent results on SUSY searches in ATLAS\n",
      "Date: 17 Jun 2024\n",
      "Abstract: {'summary': 'Supersymmetry (SUSY) provides elegant solutions to several problems in the Standard Model, and searches for SUSY particles are an important component of the LHC physics program. This talk will present the latest results from SUSY searches conducted by the ATLAS experiment. The searches target multiple final states and different assumptions about the decay mode of the produced SUSY particles, including searches for both R-parity conserving models and R-parity violating models and their possible connections with the recent observation of the flavour and muon g-2 anomalies. The talk will also highlight the employment of novel analysis techniques, including advanced machine learning techniques and special object reconstruction, that are necessary for many of these analyses to extend the sensitivity reach to challenging regions of the phase space.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Enhancing Prompt Lepton Identification: Development and Optimization of the PLIT Tagger\n",
      "Date: 11 Jun 2024\n",
      "Abstract: {'summary': \"Within the ATLAS Experiment the Prompt Lepton Isolation Tagger (PLIT) served as an essential tool to distinguish between prompt muons originating from the decays of W and Z bosons and non-prompt muons generated in the semi-leptonic decays of b- and c-hadrons. Its central role was to effectively mitigate the presence of fake and non-prompt leptons in various multi-lepton final state analyses and had been extensively used in Run-2. The poster will present the ongoing efforts in developing and optimizing this tagger for Run-3 data analyses. Through the integration of new features and the exploration of novel machine learning algorithms, the tagger's discrimination power can be enhanced, allowing for more precise identification of prompt leptons originating from electroweak boson decays.\"}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Deployment of ATLAS Calorimeter Fast Simulation Training Through Container Technology\n",
      "Date: 21 Mar 2024\n",
      "Abstract: {'summary': 'Simulation of the detector response is a major computational challenge in modern High Energy Physics experiments, as for example it accounts for about two fifths of the total ATLAS computing resources. Among simulation tasks, calorimeter simulation is the most demanding, taking up about 80% of resource use for simulation and expected to increase in the future. Solutions have been developed to cope with this demand, notably fast simulation tools based on Machine Learning (ML) techniques, which are faster than Geant4 when simulating calorimeter response and maintain a high level of accuracy. However, these ML-based models require a lot of computing resources to train. Moreover, computational resources can also be saved by deploying their training on other resources than the CERN HTCondor batch system or the Worldwide LHC Computing Grid, with the opportunity to have an additional boost in computing performance. In this work we introduce FastCaloGANtainer, a containerized version of FastCaloGAN, a fast simulation tool developed by the ATLAS Collaboration. FastCaloGANtainer allows the training of this tool on more powerful devices such as High Performance Computing clusters and reduces software dependencies on local or distributed file systems (such as CVMFS). We describe the testing methodology and the results obtained on different resources with different operating systems and installed software, with or without GPUs.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond\n",
      "Date: 21 Mar 2024\n",
      "Abstract: {'summary': 'As we are approaching the high-luminosity era of the LHC, the computational requirements of the ATLAS experiment are expected to increase significantly in the coming years. In particular, the simulation of MC events is immensely computationally demanding, and their limited availability is one of the major sources of systematic uncertainties in many physics analyses. The main bottleneck in the detector simulation is the detailed simulation of electromagnetic and hadronic showers in the ATLAS calorimeter system using Geant4. In order to increase the MC statistics and to leverage the available CPU resources for LHC Run 3, the ATLAS collaboration has recently put into production a refined and significantly improved version of its state-of-the-art fast simulation tool AtlFast3. AtlFast3 uses classical parametric and machine learning based approaches such as Generative Adversarial Networks (GANs) for the fast simulation of LHC events in the ATLAS detector. This poster presents the newly improved version of AtlFast3 that is currently in production for the simulation of Run 3 samples.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Boosting CPU Efficiency in ATLAS Inner Detector Reconstruction with Track Overlay\n",
      "Date: 19 Mar 2024\n",
      "Abstract: {'summary': 'In response to the rising CPU consumption and storage demands, as we enter a new phase in particle physics with the High-Luminosity Large Hadron Collider (HL-LHC), our efforts are centered around enhancing the CPU processing efficiency of reconstruction within the ATLAS inner detector. The track overlay approach involves pre-reconstructing pileup tracks and subsequently running reconstruction exclusively on hard-scatter tracks. This allows us to conserve valuable CPU resources by concentrating on events of interest. Integral to track overlay is the incorporation of machine learning (ML)-based decision processes. ML decisions guide the selection of events suitable for track overlay, while events in denser environments continue to use the standard overlay. This strategy ensures judicious use of resources, balancing efficiency and precision in inner detector reconstruction. This presentation focuses on constructing the ML model and verifying the workflow with ML decisions. The improvement of the track overlay approach on CPU usage in the Run 3 detector setup are also demonstrated.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: A Function-as-a-Task Workflow Management Approach with PanDA and iDDS\n",
      "Date: 19 Mar 2024\n",
      "Abstract: {'summary': \"The growing complexity of high energy physics analysis often involves running a large number of different tools. This demands a multi-step data processing approach, with each step requiring different resources and carrying dependencies on preceding steps. Itâ€™s important and useful to have a tool to automate these diverse steps efficiently. With the Production and Distributed Analysis (PanDA) system and the intelligent Data Delivery Service (iDDS), we provide a platform for coordinating sequences of tasks with a workflow, orchestrating the seamless execution of tasks in a specified order and under predefined conditions, in order to automate the task sequence. In this presentation, we will present our efforts, beginning with an overview of the platform's architecture. We'll then describe a user-friendly interface with workflows described in python and tasks described by python functions. Next, we detail the flow to transform python functions into tasks and schedule tasks to distributed heterogeneous resources, coupled with a messaging-based asynchronous result-processing mechanism. Finally, we'll showcase a practical example illustrating how this platform effectively converts a machine learning hyperparameter optimization processing on an ATLAS ttH analysis to a distributed workflow.\"}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Search for Higgs boson decays to two charm quarks at ATLAS\n",
      "Date: 15 Mar 2024\n",
      "Abstract: {'summary': 'The Higgs boson, the mass mediator in the Standard Model (SM) of particle physics, was discovered at the Large Hadron Collider (LHC) in 2012. Since then, measuring the decay from the Higgs boson to fermions and validating the SM prediction has been one of the main physics goals of the LHC. The Higgs boson to bottom quark decay ($H\\\\rightarrow b\\\\overline{b}$) has been observed by the ATLAS collaboration during the LHC second data run (Run 2). Similarly, upper limits have been set on the probability of Higgs bosons decaying to charm quarks ($H\\\\rightarrow c\\\\overline{c}$) using ATLAS Run 2 data. In this talk, we present the latest ATLAS measurement of the Higgs boson decays to charm quarks using Higgs produced in association with vector bosons ($VH\\\\rightarrow c\\\\overline{c}$). Novel machine learning techniques are used to tag charm jets. This latest ATLAS Run 2 measurement sets a stringent upper limit on $VH\\\\rightarrow c\\\\overline{c}$. In addition, the measurement is combined with the latest $VH\\\\rightarrow b\\\\overline{b}$ analysis. The combination sets the most stringent ratio between the charm and bottom Yukawa coupling modifiers ($\\\\kappa_{c}/\\\\kappa_{b}$).'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Flavor tagging performance in ATLAS and CMS with an emphasis on HH and multi-Higgs searches\n",
      "Date: 08 Mar 2024\n",
      "Abstract: {'summary': 'I didn\\'t submit an abstract this was a talk invited by the organizers, so I\\'m sharing the info for the conference (https://indico.cern.ch/event/1334055/) to show approximately what level and audience I was designing the talk for. \"COMETA (COmprehensive Multiboson Experiment-Theory Action) is a COST Action devoted to improving measurements of multi-boson production processes at the LHC and their interpretation. It brings together theorists, experimentalists and Machine Learning experts, with the goal of creating a tightly interconnected community that can boost the development of innovative approaches to multi-boson measurements. It also aims at creating an inclusive and informal environment, where young scientists and researchers based in underfunded european countries can gain international visibility.\"'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Machine learning in high energy physics at LHC\n",
      "Date: 01 Dec 2023\n",
      "Abstract: {'summary': 'In this talk, I will discuss machine learning tasks used in high energy physics. I will talk about some common ways to represent our data, including graphs, images, sequences, sets. Then I will discuss different types of learning tasks from supervised learning to unsupervised learning, and showcase some applications for these tasks.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Computational Performance of the ATLAS ITk GNN Track Reconstruction Pipeline\n",
      "Date: 18 Oct 2024\n",
      "Abstract: {'summary': 'The ATLAS event reconstruction chain is projected to increase dramatically in computational cost with the upgrade to the HL-LHC. A particularly expensive step in this chain is track finding, where energy deposits in the inner tracker (ITk) are grouped into subsets of track candidates, which can then be fitted and provided for downstream tasks. In an effort to reduce execution times and harness accelerator hardware such as GPUs, for both offline and online purposes, machine learning approaches are being developed for track finding. A first functional implementation of a graph neural network-based track pattern reconstruction for ITk has been developed, with competitive physics performance compared with traditional methods. This document describes a variety of improvements to the algorithmic implementations and machine learning models, to significantly decrease execution times from minutes to hundreds of milliseconds.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Novel ML technique applications\n",
      "Date: 29 Sep 2024\n",
      "Abstract: {'summary': 'Machine learning (ML) is a rapidly growing area of research in the field of particle physics, with a vast array of applications at the CERN LHC. ML has changed the way particle physicists conduct searches and measurements as a versatile tool used to improve existing approaches and enable fundamentally new ones. In these proceedings, we describe novel ML techniques and recent results for improved classification, fast simulation, unfolding, and anomaly detection in LHC experiments.'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: A simultaneous unbinned differential cross section measurement of twenty-four $Z$+jets kinematic observables with the ATLAS detector\n",
      "Date: 30 May 2024\n",
      "Abstract: [{'summary': '$Z$ boson events at the Large Hadron Collider can be selected with high purity and are sensitive to a diverse range of QCD phenomena. As a result, these events are often used to probe the nature of the strong force, improve Monte Carlo event generators, and search for deviations from Standard Model predictions. All previous measurements of $Z$ boson production characterize the event properties using a small number of observables and present the results as differential cross sections in predetermined bins. In this analysis, a machine learning method called OmniFold is used to produce a simultaneous measurement of twenty-four $Z$+jets observables using $139$ fb$^{-1}$ of proton-proton collisions at $\\\\sqrt{s}=13$ TeV collected with the ATLAS detector. Unlike any previous fiducial differential cross-section measurement, this result is presented unbinned as a dataset of particle-level events, allowing for flexible re-use in a variety of contexts and for new observables to be constructed from the twenty-four measured observables.'}, {'number': 'arXiv', 'summary': '$Z$ boson events at the Large Hadron Collider can be selected with high purity and are sensitive to a diverse range of QCD phenomena. As a result, these events are often used to probe the nature of the strong force, improve Monte Carlo event generators, and search for deviations from Standard Model predictions. All previous measurements of $Z$ boson production characterize the event properties using a small number of observables and present the results as differential cross sections in predetermined bins. In this analysis, a machine learning method called OmniFold is used to produce a simultaneous measurement of twenty-four $Z$+jets observables using $139$ fb$^{-1}$ of proton-proton collisions at $\\\\sqrt{s}=13$ TeV collected with the ATLAS detector. Unlike any previous fiducial differential cross-section measurement, this result is presented unbinned as a dataset of particle-level events, allowing for flexible re-use in a variety of contexts and for new observables to be constructed from the twenty-four measured observables.'}]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "if recent_results:\n",
    "    for record in recent_results:\n",
    "        # Print basic information if available\n",
    "        title = record.get('title', {}).get('title', 'No title')\n",
    "        abstract = record.get('abstract', 'No abstract')\n",
    "        date = record.get('prepublication', {}).get('date', 'No date')\n",
    "        \n",
    "        print(f\"\\nTitle: {title}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Abstract: {abstract}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'An implementation of Neural Simulation-Based Inference for Parameter Estimation in ATLAS'}\n",
      "{'title': 'Measurement of Track Functions in ATLAS Run 2 Data'}\n",
      "{'title': 'Recent Advances in the GAN-based Fast Calorimeter Simulation of the ATLAS Experiment'}\n",
      "{'title': 'Parameter Estimation in ATLAS with Neural Simulation-Based Inference'}\n",
      "{'title': 'Towards Machine-Learning Particle Flow with the ATLAS Detector at the LHC'}\n",
      "{'title': 'Improving Computational Performance of ATLAS GNN Track Reconstruction Pipeline'}\n",
      "{'title': 'ATLAS EFT Results in the Top Quark Sector'}\n",
      "{'title': 'AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond'}\n",
      "{'title': 'Boosted Higgs decays to b-quarks in ATLAS'}\n",
      "{'title': 'Performance versus uncertainty in boosted top tagging with the ATLAS detector'}\n",
      "{'title': 'Flavour Tagging with Graph Neural Network with the ATLAS Detector'}\n",
      "{'title': 'ATLAS searches for electroweak supersymmetry with compressed spectra'}\n",
      "{'title': 'Flavour Tagging with Graph Neural Network at ATLAS'}\n",
      "{'title': 'Classifying hadronic objects in ATLAS with ML/AI algorithms'}\n",
      "{'title': 'Searches for new physics using unsupervised machine learning for anomaly detection in $\\\\sqrt{s}$ = 13 TeV $pp$ collisions recorded by the ATLAS detector at the LHC'}\n",
      "{'title': 'Classifying hadronic objects in ATLAS with ML/AI algorithms'}\n",
      "{'title': 'New ATLAS $t\\\\bar{t}H(b\\\\bar{b})$ Run 2 Analysis'}\n",
      "{'title': 'The Fast Simulation Program of ATLAS at the LHC'}\n",
      "{'title': 'Enhancing Prompt Lepton Identification: Development and Optimization of the PLIT Tagger'}\n",
      "{'title': 'Searches for new phenomena using Anomaly Detection at the ATLAS experiment'}\n",
      "{'title': 'Recent results on SUSY searches in ATLAS'}\n",
      "{'title': 'Enhancing Prompt Lepton Identification: Development and Optimization of the PLIT Tagger'}\n",
      "{'title': 'Deployment of ATLAS Calorimeter Fast Simulation Training Through Container Technology'}\n",
      "{'title': 'AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond'}\n",
      "{'title': 'Boosting CPU Efficiency in ATLAS Inner Detector Reconstruction with Track Overlay'}\n",
      "{'title': 'A Function-as-a-Task Workflow Management Approach with PanDA and iDDS'}\n",
      "{'title': 'Search for Higgs boson decays to two charm quarks at ATLAS'}\n",
      "{'title': 'Flavor tagging performance in ATLAS and CMS with an emphasis on HH and multi-Higgs searches'}\n",
      "{'title': 'Machine learning in high energy physics at LHC'}\n",
      "{'title': 'Computational Performance of the ATLAS ITk GNN Track Reconstruction Pipeline'}\n",
      "{'title': 'Novel ML technique applications'}\n",
      "{'title': 'A simultaneous unbinned differential cross section measurement of twenty-four $Z$+jets kinematic observables with the ATLAS detector'}\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "\n",
    "for record in recent_results:\n",
    "    print(record[\"title\"])\n",
    "    try:\n",
    "        record[\"title\"] = record[\"title\"][\"title\"]\n",
    "        # Handle case where abstract is a list\n",
    "        if isinstance(record[\"abstract\"], list):\n",
    "            record[\"abstract\"] = record[\"abstract\"][0]\n",
    "        record[\"abstract\"] = record[\"abstract\"][\"summary\"]\n",
    "    except:\n",
    "        print(f\"No abstract for {record['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/atlas_data.json', 'w') as f:\n",
    "    json.dump(recent_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: An implementation of Neural Simulation-Based Inference for Parameter Estimation in ATLAS\n",
      "Date: 28 Oct 2024\n",
      "Abstract: Neural Simulation-Based Inference (NSBI) is a powerful class of machine learning (ML)-based methods for statistical inference that naturally handles high-dimensional parameter estimation without the need to bin data into low-dimensional summary histograms. Such methods are promising for a range of measurements, including at the Large Hadron Collider (LHC), where no single observable may be optimal to scan over the entire theoretical phase space under consideration, or where binning data into histograms could result in a loss of sensitivity. This work develops an NSBI framework for statistical inference, using neural networks to estimate probability density ratios, which enables the application of NSBI to a full-scale LHC analysis. It incorporates a large number of systematic uncertainties, quantifies the uncertainty coming from finite training statistics, develops a method to construct confidence intervals, and demonstrates a series of intermediate diagnostic checks that can be performed to validate the robustness of the method. As an example, the power and feasibility of the method are demonstrated on simulated data for a simplified version of an off-shell Higgs boson couplings measurement in the four-leptons final states. This NSBI framework is an extension of the standard statistical framework used by LHC experiments and can benefit a large number of physics analyses.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Measurement of Track Functions in ATLAS Run 2 Data\n",
      "Date: 30 Jul 2024\n",
      "Abstract: Measurements of jet substructure are key to probing the energy frontier at colliders, and many of them use track-based observables which take advantage of the angular precision of tracking detectors. Theoretical calculations of track-based observables require ``track functions'', which characterize the transverse momentum fraction $r_q$ carried by charged hadrons from a fragmenting quark or gluon. This letter presents a direct measurement of $r_q$ distributions in dijet events from the $140$ fb$^{-1}$ of $\\sqrt{s}~=~13$ TeV proton-proton collisions collected by the ATLAS detector. The first six moments of the $r_q$ distribution are extracted and demixed based on theory predictions to present values for quark and gluon jets separately. The data are corrected for detector effects based on machine-learning methods. The scale evolution of the moments of the $r_q$ distribution provides direct access to non-linear renormalization group evolution equations of QCD, and is compared with analytic predictions. When incorporated into future theoretical calculations, these results will enable a precision program of theory-data comparison for track-based jet substructure observables.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Recent Advances in the GAN-based Fast Calorimeter Simulation of the ATLAS Experiment\n",
      "Date: 28 Oct 2024\n",
      "Abstract: Simulation of the detector response is a major computational challenge in modern High-Energy Physics experiments, accounting for about 40% of the total computational resources used in ATLAS. The simulation of the calorimeter response is particularly demanding, consuming about 80% of the total simulation time. In order to make the best use of the available computational resources, fast simulation tools based on Machine Learning techniques have been developed to simulate the calorimeter response faster than Geant4 while maintaining a high level of accuracy. One such tool, developed by the ATLAS Collaboration and currently in production for LHC Run 3, is FastCaloGAN, which uses Generative Adversarial Networks (GANs) to generate electromagnetic and hadronic showers. To facilitate the training and optimisation of the GANs, and to enable a more efficient use of computational resources, a container-based system, FastCaloGANtainer, facilitates the deployment of the FastCaloGAN training on complementary high-performance resources such as High Performance Computing (HPC) farms and ensures its operational independence from the underlying system. This talk presents the latest developments in FastCaloGAN and FastCaloGANtainer, discussing their technical details and recent improvements in terms of Physics and computational performance. For FastCaloGAN, these improvements include an improved voxelisation and extension to further use cases (e.g. particle types not yet covered), while for FastCaloGANtainer they concern its deployment on a wider variety of resources with multi-CPU/GPU nodes and different architectures (including cutting-edge HPC clusters such as Leonardo at CINECA in Bologna, Italy).\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Parameter Estimation in ATLAS with Neural Simulation-Based Inference\n",
      "Date: 28 Oct 2024\n",
      "Abstract: Neural Simulation-Based Inference (NSBI) is a powerful class of machine learning (ML)-based methods for statistical inference that naturally handle high dimensional parameter estimation without the need to bin data into low-dimensional summary histograms. Such methods are promising for a range of measurements at the Large Hadron Collider, where no single observable may be optimal to scan over the entire theoretical phase space under consideration, or where binning data into histograms could result in a loss of sensitivity. This work develops an NSBI framework that, for the first time, allows NSBI to be applied to a full-scale LHC analysis, by successfully incorporating a large number of systematic uncertainties, quantifying the uncertainty coming from finite training statistics, developing a method to construct confidence intervals, and demonstrating a series of intermediate diagnostic checks that can be performed to validate the robustness of the method. As an example, the power and feasibility of the method are demonstrated for an off-shell Higgs boson couplings measurement in the four lepton decay channel, using simulated samples. The proposed method is a generalisation of the standard statistical framework at the LHC, and can benefit a large number of physics analyses. This work serves as a blueprint for measurements at the LHC using NSBI.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Towards Machine-Learning Particle Flow with the ATLAS Detector at the LHC\n",
      "Date: 28 Oct 2024\n",
      "Abstract: Particle flow reconstruction at colliders combines various detector subsystems (typically the calorimeter and tracker) to provide a combined event interpretation that utilizes the strength of each detector. The accurate association of redundant measurements of the same particle between detectors is the key challenge in this technique. This contribution describes recent progress in the ATLAS experiment towards utilizing machine-learning to improve particle flow in the ATLAS detector. In particular, point-cloud techniques are utilized to associate measurements from the same particle, leading to reduced confusion compared to baseline techniques. Next steps towards further testing and implementation will be discussed.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Improving Computational Performance of ATLAS GNN Track Reconstruction Pipeline\n",
      "Date: 28 Oct 2024\n",
      "Abstract: Track reconstruction is an essential element of modern and future collider experiments, including the ATLAS detector. The HL-LHC upgrade of the ATLAS detector brings an unprecedented tracking reconstruction challenge, both in terms of the large number of silicon hit cluster readouts and the throughput required for budget-constrained track reconstruction. Traditional track reconstruction techniques often contain steps that scale combinatorically, which could be ameliorated with deep learning approaches. The GNN4ITk project has been shown to apply geometric deep learning algorithms for tracking to a similar level of physics performance with traditional techniques while scaling sub-quadratically. In this contribution, we compare the computational performance of a variety of pipeline configurations and machine learning inference methods. These include heuristic-and-ML-based graph segmentation techniques, GPU-based module map graph construction, and studies of high throughput graph convolutional kernels. In this contribution, we present benchmarks of latency, throughput, memory usage, and power consumption of each pipeline configuration.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: ATLAS EFT Results in the Top Quark Sector\n",
      "Date: 28 Oct 2024\n",
      "Abstract: The overview summarises the latest Effective Field Theory (EFT) analyses conducted by the ATLAS experiment, focusing on latest results in constraining physics beyond the Standard Model using precision measurements. Emphasis is placed on the top quark sector, where EFT provides a powerful framework for interpreting deviations in top quark production and decay processes. We highlight three of the most recent results: constraints on EFT operators from ttgamma production, charged lepton flavour violation, and single top production in t-channel. These analyses employ advanced statistical techniques, machine learning methods, and state-of-the-art Monte Carlo simulations to achieve optimal sensitivity to potential new physics effects.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond\n",
      "Date: 25 Oct 2024\n",
      "Abstract: As we are approaching the high-luminosity era of the LHC, the computational requirements of the ATLAS experiment are expected to increase significantly in the coming years. In particular, the simulation of MC events is immensely computationally demanding, and their limited availability is one of the major sources of systematic uncertainties in many physics analyses. The main bottleneck in the detector simulation is the detailed simulation of electromagnetic and hadronic showers in the ATLAS calorimeter system using Geant4. In order to increase the MC statistics and to leverage the available CPU resources for LHC Run 3, the ATLAS collaboration has recently put into production a refined and significantly improved version of its state-of-the-art fast simulation tool AtlFast3. AtlFast3 uses classical parametric and machine learning based approaches such as Generative Adversarial Networks (GANs) for the fast simulation of LHC events in the ATLAS detector. This talk will present the newly improved version of AtlFast3 that is currently in production for the simulation of Run 3 samples. In addition, ideas and plans for the future of fast simulation in ATLAS will also be discussed.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Boosted Higgs decays to b-quarks in ATLAS\n",
      "Date: 25 Sep 2024\n",
      "Abstract: The Higgs boson, central to the Standard model, is a powerful probe for new physics theories. Precise measurements of the Higgs coupling to the third generation particles could reveal deviations from the Standard Model predictions, potentially leading to the discovery of new physics processes, especially at high energy. Investigating the Higgs decaying into a pair of b-quarks is advantageous due to the high branching ratio which provides a large dataset, facilitating the investigation of the boosted regime at high pT, above 400 GeV. This talk will present recent results from the ATLAS collaboration of the Higgs boson decays to b-quarks analysis with an emphasis on machine learning techniques, crucial to enhance the precision of high pT measurements.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Performance versus uncertainty in boosted top tagging with the ATLAS detector\n",
      "Date: 10 Sep 2024\n",
      "Abstract: The identification of top quark decays, known as top tagging, is a crucial component in many measurements and searches at the Large Hadron Collider (LHC). Recently machine learning techniques have greatly improved the performance of top tagging algorithms. This poster presents the performance of several machine learning based jet tagging methods. In particular the performance of a Lund jet plane based tagger is compared to existing baselines. Then the systematic uncertainties in network performance are estimated through an approximate procedure that allows the size of the produced uncertainties to be quantified along with the raw performance. The most performant algorithms are found to produce the largest uncertainties, motivating the development of methods to reduce these uncertainties without compromising performance.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Flavour Tagging with Graph Neural Network with the ATLAS Detector\n",
      "Date: 10 Sep 2024\n",
      "Abstract: Flavour-tagging is a critical component of the ATLAS experiment physics programme. Existing flavour tagging algorithms rely on several low-level taggers, which are a combination of physically informed algorithms and machine learning models. A novel approach presented here instead uses a single machine learning model based on reconstructed tracks, avoiding the need for low-level taggers based on secondary vertexing algorithms. This new approach reduces complexity and improves tagging performance. This model employs a transformer architecture to process information from a variable number of tracks and other objects in the jet in order to simultaneously predict the jets flavour, the partitioning of tracks into vertices, and the physical origin of each track. The inclusion of auxiliary tasks aids the models interpretability. The new approach significantly improves jet flavour identification performance compared to existing methods in both Monte-Carlo simulation and collision data. Notably, the versatility of the approach is demonstrated by its successful application in boosted Higgs tagging using large-R jets.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: ATLAS searches for electroweak supersymmetry with compressed spectra\n",
      "Date: 03 Sep 2024\n",
      "Abstract: Supersymmetry (SUSY) models with featuring small mass splittings between one or more particles and the lightest neutralino could solve the hierarchy problem as well as offer a suitable dark matter candidate consistent with the observed thermal-relic dark matter density. However, the detection of SUSY higgsinos at the LHC remains challenging especially if their mass-splitting is O(1 GeV) or lower. Searches are developed using 140 fb^{-1} of proton-proton collision data collected by the ATLAS Detector at a center-of-mass energy \\sqrt{s}=13 TeV to overcome the challenge. Novel techniques are developed exploiting machine-learning techniques, low-momentum tracks with large transverse impact parameters, or topologies consistent with VBF production of the supersymmetric particles. Results are interpreted in terms of SUSY simplified models and, for the first time since the LEP era, several gaps in different ranges of mass-splittings are excluded.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Computational Performance of the ATLAS ITk GNN Track Reconstruction Pipeline\n",
      "Date: 18 Oct 2024\n",
      "Abstract: The ATLAS event reconstruction chain is projected to increase dramatically in computational cost with the upgrade to the HL-LHC. A particularly expensive step in this chain is track finding, where energy deposits in the inner tracker (ITk) are grouped into subsets of track candidates, which can then be fitted and provided for downstream tasks. In an effort to reduce execution times and harness accelerator hardware such as GPUs, for both offline and online purposes, machine learning approaches are being developed for track finding. A first functional implementation of a graph neural network-based track pattern reconstruction for ITk has been developed, with competitive physics performance compared with traditional methods. This document describes a variety of improvements to the algorithmic implementations and machine learning models, to significantly decrease execution times from minutes to hundreds of milliseconds.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Novel ML technique applications\n",
      "Date: 29 Sep 2024\n",
      "Abstract: Machine learning (ML) is a rapidly growing area of research in the field of particle physics, with a vast array of applications at the CERN LHC. ML has changed the way particle physicists conduct searches and measurements as a versatile tool used to improve existing approaches and enable fundamentally new ones. In these proceedings, we describe novel ML techniques and recent results for improved classification, fast simulation, unfolding, and anomaly detection in LHC experiments.\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: A simultaneous unbinned differential cross section measurement of twenty-four $Z$+jets kinematic observables with the ATLAS detector\n",
      "Date: 30 May 2024\n",
      "Abstract: $Z$ boson events at the Large Hadron Collider can be selected with high purity and are sensitive to a diverse range of QCD phenomena. As a result, these events are often used to probe the nature of the strong force, improve Monte Carlo event generators, and search for deviations from Standard Model predictions. All previous measurements of $Z$ boson production characterize the event properties using a small number of observables and present the results as differential cross sections in predetermined bins. In this analysis, a machine learning method called OmniFold is used to produce a simultaneous measurement of twenty-four $Z$+jets observables using $139$ fb$^{-1}$ of proton-proton collisions at $\\sqrt{s}=13$ TeV collected with the ATLAS detector. Unlike any previous fiducial differential cross-section measurement, this result is presented unbinned as a dataset of particle-level events, allowing for flexible re-use in a variety of contexts and for new observables to be constructed from the twenty-four measured observables.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "if recent_results:\n",
    "    for record in recent_results:\n",
    "        # Print basic information if available\n",
    "        title = record.get('title', 'No title')\n",
    "        abstract = record.get('abstract', 'No abstract')\n",
    "        date = record.get('prepublication', {}).get('date', 'No date')\n",
    "        \n",
    "        print(f\"\\nTitle: {title}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Abstract: {abstract}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Search Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'p1': 'machine learning',\n",
    "    'f1': 'abstract',\n",
    "    'rg': 100,\n",
    "    'c': ['ATLAS', 'CMS', 'LHCb', 'ALICE']\n",
    "}\n",
    "results = search_cds(\n",
    "        params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_results = filter_recent_records(results)\n",
    "len(recent_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Searches for New Physics with top quarks using the ATLAS detector\n",
      "Date: 29 Oct 2024\n",
      "Abstract: {'summary': 'Due to its large mass, the top quark plays a crucial role in probing the Standard Model of particle physics and beyond. The latest results from searches for new physics using top quark events collected with the ATLAS detector at the Large Hadron Collider are presented. In particular, the focus lies on scenarios beyond the Standard Model where the top quark provides is a powerful probe to answer open questions on Dark Matter and the light mass of the Higgs Boson. All searches presented utilize the full Run-2 dataset from the LHC, employing advanced techniques such as machine learning to provide the best sensitivity to new physics.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Recent Advances in the GAN-based Fast Calorimeter Simulation of the ATLAS Experiment\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Simulation of the detector response is a major computational challenge in modern High-Energy Physics experiments, accounting for about 40% of the total computational resources used in ATLAS. The simulation of the calorimeter response is particularly demanding, consuming about 80% of the total simulation time. In order to make the best use of the available computational resources, fast simulation tools based on Machine Learning techniques have been developed to simulate the calorimeter response faster than Geant4 while maintaining a high level of accuracy. One such tool, developed by the ATLAS Collaboration and currently in production for LHC Run 3, is FastCaloGAN, which uses Generative Adversarial Networks (GANs) to generate electromagnetic and hadronic showers. To facilitate the training and optimisation of the GANs, and to enable a more efficient use of computational resources, a container-based system, FastCaloGANtainer, facilitates the deployment of the FastCaloGAN training on complementary high-performance resources such as High Performance Computing (HPC) farms and ensures its operational independence from the underlying system. This talk presents the latest developments in FastCaloGAN and FastCaloGANtainer, discussing their technical details and recent improvements in terms of Physics and computational performance. For FastCaloGAN, these improvements include an improved voxelisation and extension to further use cases (e.g. particle types not yet covered), while for FastCaloGANtainer they concern its deployment on a wider variety of resources with multi-CPU/GPU nodes and different architectures (including cutting-edge HPC clusters such as Leonardo at CINECA in Bologna, Italy).'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Parameter Estimation in ATLAS with Neural Simulation-Based Inference\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Neural Simulation-Based Inference (NSBI) is a powerful class of machine learning (ML)-based methods for statistical inference that naturally handle high dimensional parameter estimation without the need to bin data into low-dimensional summary histograms. Such methods are promising for a range of measurements at the Large Hadron Collider, where no single observable may be optimal to scan over the entire theoretical phase space under consideration, or where binning data into histograms could result in a loss of sensitivity. This work develops an NSBI framework that, for the first time, allows NSBI to be applied to a full-scale LHC analysis, by successfully incorporating a large number of systematic uncertainties, quantifying the uncertainty coming from finite training statistics, developing a method to construct confidence intervals, and demonstrating a series of intermediate diagnostic checks that can be performed to validate the robustness of the method. As an example, the power and feasibility of the method are demonstrated for an off-shell Higgs boson couplings measurement in the four lepton decay channel, using simulated samples. The proposed method is a generalisation of the standard statistical framework at the LHC, and can benefit a large number of physics analyses. This work serves as a blueprint for measurements at the LHC using NSBI.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Towards Machine-Learning Particle Flow with the ATLAS Detector at the LHC\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Particle flow reconstruction at colliders combines various detector subsystems (typically the calorimeter and tracker) to provide a combined event interpretation that utilizes the strength of each detector. The accurate association of redundant measurements of the same particle between detectors is the key challenge in this technique. This contribution describes recent progress in the ATLAS experiment towards utilizing machine-learning to improve particle flow in the ATLAS detector. In particular, point-cloud techniques are utilized to associate measurements from the same particle, leading to reduced confusion compared to baseline techniques. Next steps towards further testing and implementation will be discussed.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Improving Computational Performance of ATLAS GNN Track Reconstruction Pipeline\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Track reconstruction is an essential element of modern and future collider experiments, including the ATLAS detector. The HL-LHC upgrade of the ATLAS detector brings an unprecedented tracking reconstruction challenge, both in terms of the large number of silicon hit cluster readouts and the throughput required for budget-constrained track reconstruction. Traditional track reconstruction techniques often contain steps that scale combinatorically, which could be ameliorated with deep learning approaches. The GNN4ITk project has been shown to apply geometric deep learning algorithms for tracking to a similar level of physics performance with traditional techniques while scaling sub-quadratically. In this contribution, we compare the computational performance of a variety of pipeline configurations and machine learning inference methods. These include heuristic-and-ML-based graph segmentation techniques, GPU-based module map graph construction, and studies of high throughput graph convolutional kernels. In this contribution, we present benchmarks of latency, throughput, memory usage, and power consumption of each pipeline configuration.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: ATLAS EFT Results in the Top Quark Sector\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'The overview summarises the latest Effective Field Theory (EFT) analyses conducted by the ATLAS experiment, focusing on latest results in constraining physics beyond the Standard Model using precision measurements. Emphasis is placed on the top quark sector, where EFT provides a powerful framework for interpreting deviations in top quark production and decay processes. We highlight three of the most recent results: constraints on EFT operators from ttgamma production, charged lepton flavour violation, and single top production in t-channel. These analyses employ advanced statistical techniques, machine learning methods, and state-of-the-art Monte Carlo simulations to achieve optimal sensitivity to potential new physics effects.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: The ATLAS inner detector trigger performance in Run 3\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': \"The performance of the inner detector (ID) tracking trigger of the ATLAS experiment at the Large Hadron Collider (LHC) is presented, evaluated using early Run 3 data. Included are results from the evolved standard trigger track reconstruction, and from new unconventional tracking strategies used for the first time in the Run 3 trigger. The application of ID tracking in the Run 3 trigger is significantly expanded, in particular full-detector tracking is utilized for hadronic signatures such as jets and missing transverse energy triggers, for the first time. To meet computing resource limitations, new features have been developed. These include machine-learning additions for the track seeding, together with many additional improvements with respect to the trigger tracking used in LHC Run 2. As the world's highest-energy particle accelerator, the LHC provides a unique opportunity for directly searching for new physics beyond the Standard Model. Massive long-lived particles (LLPs), which are absent in the Standard Model are present in many well-motivated theories of beyond-the-Standard-Model physics. These new massive LLPs can decay into other particles far from the LHC interaction region, resulting in novel experimental signatures and so require new complex techniques for their identification. Prior to Run 3, the ATLAS trigger did not include dedicated tracking triggers for the explicit identification of massive LLPs decaying in the inner tracking detectors. To enhance the sensitivity of such searches, a series of new triggers were developed for the Run 3 data taking in 2022. These included various novel unconventional tracking signatures, such as those for displaced tracks, displaced jets, or short tracks which disappear within the ID tracking volume. With these developments, the high performance of the ID trigger remains essential for the ATLAS physics programme in Run 3, both for precision measurements of the Standard Model and now also searches for new physics beyond the Standard Model.\"}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: An implementation of Neural Simulation-Based Inference for Parameter Estimation in ATLAS\n",
      "Date: 28 Oct 2024\n",
      "Abstract: {'summary': 'Neural Simulation-Based Inference (NSBI) is a powerful class of machine learning (ML)-based methods for statistical inference that naturally handles high-dimensional parameter estimation without the need to bin data into low-dimensional summary histograms. Such methods are promising for a range of measurements, including at the Large Hadron Collider (LHC), where no single observable may be optimal to scan over the entire theoretical phase space under consideration, or where binning data into histograms could result in a loss of sensitivity. This work develops an NSBI framework for statistical inference, using neural networks to estimate probability density ratios, which enables the application of NSBI to a full-scale LHC analysis. It incorporates a large number of systematic uncertainties, quantifies the uncertainty coming from finite training statistics, develops a method to construct confidence intervals, and demonstrates a series of intermediate diagnostic checks that can be performed to validate the robustness of the method. As an example, the power and feasibility of the method are demonstrated on simulated data for a simplified version of an off-shell Higgs boson couplings measurement in the four-leptons final states. This NSBI framework is an extension of the standard statistical framework used by LHC experiments and can benefit a large number of physics analyses.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Treatment of systematic uncertainties in $b$-jet identification and measurement of Higgs boson decays to $b$-quarks with the ATLAS detector\n",
      "Date: No date\n",
      "Abstract: {'summary': 'The Higgs boson was discovered in 2012, and since then the ATLAS and CMS collaborations have been analyzing an ever increasing number of collisions from the LHC collider to pin down the properties of this particle as precisely as possible. Among the measurements performed, especially interesting is the measurement of the Higgs boson decays to two $b$-quarks. However, this decay mode is hard to observe because of the large background from multi-jet production. To measure the Higgs boson decaying to two $b$-quarks, the best Higgs boson production channel is the associated production with a vector boson (VH) where one vector boson, either the W or Z boson, is produced in association with a Higgs boson. If the vector boson decays leptonically into neutrinos or changed leptons, the leptons will provide a handle to reduce the large multi-jet background. This thesis work involves multiple efforts on increasing the signal significance of the VH, H$\\\\rightarrow$bb analysis including optimizing the event selection, adding a new control region for the top background and using machine learning methods to purify the W+jets background in a dedicated control region and ultimately to get a better constraint on the normalization factor for this background. Each attempt increases the signal significance of the analysis by several percent. Apart from the H$\\\\rightarrow$bb analysis work, the thesis work also involves inventing two new approaches to treat systematic uncertainties related to $b$-jet identification, which plays a crucial role in enabling the H$\\\\rightarrow$bb measurement and also in many other ATLAS analyses. The first allows for the correct correlation of b-jet identification systematic uncertainties across multiple analyses. The second new treatment provides an estimate of the systematic uncertainties on identifying b-jets with especially large transverse momentum. This is particularly relevant for events in the â€œboostedâ€ VH, H$\\\\rightarrow$bb analyses'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond\n",
      "Date: 25 Oct 2024\n",
      "Abstract: {'summary': 'As we are approaching the high-luminosity era of the LHC, the computational requirements of the ATLAS experiment are expected to increase significantly in the coming years. In particular, the simulation of MC events is immensely computationally demanding, and their limited availability is one of the major sources of systematic uncertainties in many physics analyses. The main bottleneck in the detector simulation is the detailed simulation of electromagnetic and hadronic showers in the ATLAS calorimeter system using Geant4. In order to increase the MC statistics and to leverage the available CPU resources for LHC Run 3, the ATLAS collaboration has recently put into production a refined and significantly improved version of its state-of-the-art fast simulation tool AtlFast3. AtlFast3 uses classical parametric and machine learning based approaches such as Generative Adversarial Networks (GANs) for the fast simulation of LHC events in the ATLAS detector. This talk will present the newly improved version of AtlFast3 that is currently in production for the simulation of Run 3 samples. In addition, ideas and plans for the future of fast simulation in ATLAS will also be discussed.'}\n",
      "Experiment: ATLAS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Anomaly detection in CMS\n",
      "Date: 22 Oct 2024\n",
      "Abstract: {'summary': 'With current advancements in computational resources and algorithmic developments, the CMS experiment at the LHC has been incorporating machine learning (ML) techniques to further enhance its physics potential. While ML offers powerful computational tools, the foundational building blocks remain rooted in the underlying physics phenomena. These advancements have significantly improved the search for new physics, allowing physicists to conduct more effective searches and measurements while enabling innovative approaches to data analysis. In these proceedings, we present our recent advancements in ML techniques applied to anomaly detection within the CMS experiment, focusing on both dijet final states and enhancements at the Level-1 (L1) trigger. Our work includes novel methods for identifying anomalous jet substructures, enhancing the discovery potential of new physics signatures that were previously unexplored. Additionally, we discuss the implementation of ML for anomaly detection at the L1 trigger, underscoring its potential to improve the early selection of interesting events. Our findings illustrate the efficacy of these approaches in maximizing sensitivity to rare events, contributing to the ongoing efforts to unravel the mysteries of the universe.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Run 3 commissioning results of heavy-flavor jet tagging at $\\sqrt{s}=$ 13.6 TeV with CMS data using a modern framework for data processing\n",
      "Date: 22 Oct 2024\n",
      "Abstract: {'summary': 'The identification of jets arising from heavy-flavor (bottom or charm) quarks primarily relies on detector inputs from reconstructed charged particle tracks and information about secondary vertices contained within reconstructed jets. In Run 3, improved machine-learning techniques have been introduced to distinguish heavy-flavor jets from those originating from the hadronization of light-flavor (uds) quarks or gluons (g). Therefore, it is crucial to compare the distributions of data and simulations of input variables, tagging discriminants, and other pertinent kinematic observables between data and simulated events. In this proceeding, five selections to enriched different processes are presented  top quark-antiquark production ($t\\\\bar{t}$) in the dileptonic final state (enriched in b jets), in the semileptonic final state (enriched in b and c jets), W boson plus charm production (enriched in c jets), Drell-Yan production, and QCD multijet production (enriched in light-flavor jets).  These selections are shown with proton-proton collision data at $\\\\sqrt{s}=13.6$\\\\,TeV corresponding to an integrated luminosity of 61.7\\\\,$\\\\text{fb}^{-1}$ and recorded by the CMS experiment in 2022 and 2023. These studies rely on a modern and fast framework. It has been developed and automated to produce the comparisons presented, along with its technical details.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Anomaly detection in CMS\n",
      "Date: 22 Oct 2024\n",
      "Abstract: {'summary': 'With current advancements in computational resources and algorithmic developments, the CMS experiment at the LHC has been incorporating machine learning (ML) techniques to further enhance its physics potential. While ML offers powerful computational tools, the foundational building blocks remain rooted in the underlying physics phenomena. These advancements have significantly improved the search for new physics, allowing physicists to conduct more effective searches and measurements while enabling innovative approaches to data analysis. In these proceedings, we present our recent advancements in ML techniques applied to anomaly detection within the CMS experiment, focusing on both dijet final states and enhancements at the Level-1 (L1) trigger. Our work includes novel methods for identifying anomalous jet substructures, enhancing the discovery potential of new physics signatures that were previously unexplored. Additionally, we discuss the implementation of ML for anomaly detection at the L1 trigger, underscoring its potential to improve the early selection of interesting events. Our findings illustrate the efficacy of these approaches in maximizing sensitivity to rare events, contributing to the ongoing efforts to unravel the mysteries of the universe.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Search for charged lepton flavor violation in top quark interaction with an up-type quark, a muon, and a $\\tau$ lepton with the CMS experiment\n",
      "Date: 09 Oct 2024\n",
      "Abstract: {'summary': 'A search for charged-lepton flavor violation (CLFV) in top quark (t)\\ninteractions is presented.\\nProton-proton collision data collected with the CMS experiment corresponding to an integrated luminosity of 138 fb$^{-1}$ are used.\\nThe analysis selects events containing a single muon, a hadronically decaying $\\\\tau$ lepton, and three jets where one has been identified to originate from the fragmentation of a bottom quark.\\nMachine learning multiclass classification techniques are used to distinguish signal from\\nstandard model background events.\\nThe results of this search are consistent with the standard model expectations.\\nThe upper limits at 95\\\\% confidence level on the branching fraction $\\\\mathcal{B}$  for CLFV top quark decays to a muon, a $\\\\tau$ lepton, and an up or a charm quark are $\\\\mathcal{B}(\\\\mathrm{t} \\\\to \\\\mu\\\\tau\\\\mathrm{u}) < (0.04$, $0.078$, and $0.118) \\\\times 10^{-6}$, and $\\\\mathcal{B}(\\\\mathrm{t} \\\\to \\\\mu\\\\tau\\\\mathrm{c}) < (0.81$, $1.71$, and $2.05) \\\\times 10^{-6}$ for scalar, vector, and tensor-like operators, respectively.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Performance of the CMS high-level trigger during LHC Run 2\n",
      "Date: 22 Oct 2024\n",
      "Abstract: [{'summary': 'The CERN LHC provided proton and heavy ion collisions during its Run 2 operation period from 2015 to 2018. Proton-proton collisions reached a peak instantaneous luminosity of 2.1 $ \\\\times $ 10$^{34}$ cm$^{-2}$s$^{-1} $, twice the initial design value, at $ \\\\sqrt{s}= $ 13 TeV. The CMS experiment records a subset of the collisions for further processing as part of its online selection of data for physics analyses, using a two-level trigger system: the Level-1 trigger, implemented in custom-designed electronics, and the high-level trigger, a streamlined version of the offline reconstruction software running on a large computer farm. This paper presents the performance of the CMS high-level trigger system during LHC Run 2 for physics objects, such as leptons, jets, and missing transverse momentum, which meet the broad needs of the CMS physics program and the challenge of the evolving LHC and detector conditions. Sophisticated algorithms that were originally used in offline reconstruction were deployed online. Highlights include a machine-learning b tagging algorithm and a reconstruction algorithm for tau leptons that decay hadronically.'}, {'number': 'arXiv', 'summary': 'The CERN LHC provided proton and heavy ion collisions during its Run 2 operation period from 2015 to 2018. Proton-proton collisions reached a peak instantaneous luminosity of 2.1 $\\\\times$ 10$^{34}$ cm$^{-2}$s$^{-1}$, twice the initial design value, at $\\\\sqrt{s}$ = 13 TeV. The CMS experiment records a subset of the collisions for further processing as part of its online selection of data for physics analyses, using a two-level trigger system: the Level-1 trigger, implemented in custom-designed electronics, and the high-level trigger, a streamlined version of the offline reconstruction software running on a large computer farm. This paper presents the performance of the CMS high-level trigger system during LHC Run 2 for physics objects, such as leptons, jets, and missing transverse momentum, which meet the broad needs of the CMS physics program and the challenge of the evolving LHC and detector conditions. Sophisticated algorithms that were originally used in offline reconstruction were deployed online. Highlights include a machine-learning b tagging algorithm and a reconstruction algorithm for tau leptons that decay hadronically.'}]\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: FlashSim\n",
      "Date: 14 Oct 2024\n",
      "Abstract: {'summary': 'FlashSim is a Machine Learning based, end-to-end event simulation framework. It is being actively developed and optimized to meet the increasing demands of simulated samples, both now and in the near HL-LHC future.\\nIt is a fully agnostic, not analysis specific framework, trained on CMS, Geant4-based Full Simultation, going from (NANO)GEN to NANOAODSIM at O(100) Hz speed, with the aim to deliver a dataset in NANOAOD format at FastSim  (or better) accuracy. \\nThe following is an intermediate report of the status of FlashSim development.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Machine learning based tau lepton identification for the CMS high-level trigger deployed for 13.6 TeV proton-proton collisions\n",
      "Date: 30 Sep 2024\n",
      "Abstract: {'summary': 'Tau leptons are important to several testable predictions of the standard model, including lepton spin polarization, and the Higgs Yukawa coupling to leptons. Tau leptons are also vital in the search for beyond the standard model physics, as many models predict new particles which decay into final states with tau leptons. An efficient tau lepton trigger is therefore essential to maximize the physics reach of the CMS experiment. The latest online reconstruction algorithms used to trigger on tau leptons with the CMS detector that utilize machine learning based methods for the first time are described here. The performance of the algorithms is validated using 62 fb$^{-1}$ of proton-proton collisions data collected by the CMS detector in 2022 and 2023 at the unprecedented centre-of-mass energy of 13.6 TeV.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Novel ML technique applications\n",
      "Date: 29 Sep 2024\n",
      "Abstract: {'summary': 'Machine learning (ML) is a rapidly growing area of research in the field of particle physics, with a vast array of applications at the CERN LHC. ML has changed the way particle physicists conduct searches and measurements as a versatile tool used to improve existing approaches and enable fundamentally new ones. In these proceedings, we describe novel ML techniques and recent results for improved classification, fast simulation, unfolding, and anomaly detection in LHC experiments.'}\n",
      "Experiment: ALICE,ATLAS,CMS,LHCB\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Identification of Lorentz-boosted jets in the CMS experiment\n",
      "Date: 16 Sep 2024\n",
      "Abstract: {'summary': 'A focus of the CMS research involves identifying jets originated from quarks and gluons produced in high-energy proton-proton collisions. At the electroweak scale, resonances like the Z and W bosons, as well as the Higgs boson, are often produced with a significant Lorentz boost, causing their decay products to form  large and massive jets, typically reconstructed as AK8 jets. Identifying the particle that initiates these jets is essential for distinguishing boosted bosons from the QCD background.  This proceeding provides an overview of the use of boosted jet taggers in CMS, emphasizing new machine learning techniques. Additionally, it presents the validation of ML-based taggers for AK8 jets from boosted resonances decaying into b$\\\\Bar{\\\\text{b}}$, comparing CMS data with simulations.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Identification of Lorentz-boosted jets in the CMS experiment\n",
      "Date: 16 Sep 2024\n",
      "Abstract: {'summary': 'A focus of the CMS research involves identifying jets originated from quarks and gluons produced in high-energy proton-proton collisions. At the electroweak scale, resonances like the Z and W bosons, as well as the Higgs boson, are often produced with a significant Lorentz boost, causing their decay products to form  large and massive jets, typically reconstructed as AK8 jets. Identifying the particle that initiates these jets is essential for distinguishing boosted bosons from the QCD background.  This proceeding provides an overview of the use of boosted jet taggers in CMS, emphasizing new machine learning techniques. Additionally, it presents the validation of ML-based taggers for AK8 jets from boosted resonances decaying into b$\\\\Bar{\\\\text{b}}$, comparing CMS data with simulations.'}\n",
      "Experiment: CMS\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: The flash-simulation paradigm and its implementation based on Deep Generative Models for the LHCb experiment at CERN\n",
      "Date: No date\n",
      "Abstract: {'summary': 'The LHCb experiment is dedicated to precision measurements of hadrons containing $b$ and $c$ quarks at the Large Hadron Collider (LHC) at CERN. During the first two Runs of the LHC, spanning from 2010 to 2018, the LHCb Collaboration invested more than 90% of the computing budget to simulate the detector response to the traversing particles produced in heavy hadron decays. Since 2022, the LHCb experiment has relied on a renewed detector and a novel data-acquisition strategy designed to acquire data at a rate enhanced by a factor of ten. Enabling an equivalent increase in simulation production is a major challenge, requiring a technological shift and diversifying the simulation strategies for specific purposes. Data processing and data analysis technologies have been evolving quickly during the last ten years. New industrial standards and huge communities behind open-source software projects arose, transforming the landscape of computer science and data processing. The fast development of Machine Learning and Cloud technologies provides modern solutions to address challenges well known to the High Energy Physics community, operating distributed data processing software on the nodes of the Worldwide LHC Computing Grid for the last three decades. In this Thesis, I present a study to adopt these new technologies to evolve the LHCb simulation software using machine learning models trained on multi-cloud resources to parameterize the detector response and the effects induced by the reconstruction algorithms. The resulting detector simulation approach is known as flash-simulation and represents the most challenging and radical option in the landscape of opportunities to accelerate the detector simulation. To encode in a machine learning model the intrinsic randomness of the quantum interactions occurring within the detector, the experimental uncertainties, and the effect of missing variables, parameterizations are designed as Generative Models, and in particular as Generative Adversarial Networks. The Lamarr project, arising as the official flash-simulation option of the LHCb experiment, enables connecting the trained models in long data-processing pipelines to simulate various effects in the detection and reconstruction procedure. Pipelines can be deployed in the LHCb Simulation software stack by relying on the same physics generators as the other simulation approaches and serializing the results with the format of the official reconstruction software. In this Thesis, I address the most compelling challenges in the design of a flash-simulation solution, including the identification of a strategy to train and validate reliable parameterizations, the definition and distribution of heavy hyperparameter optimization campaigns through opportunistic computing resources, the combination of multiple parameterizations in a data processing pipeline, and its deployment in the software stack of one of the major experiments at the LHC. Future work will extend the validation of flash-simulation techniques for additional heavy hadrons, decay modes, and data-taking conditions, paving the way to the widespread adoption of flash-simulations and contributing to a significant decrease in the average computational cost of detector simulation.'}\n",
      "Experiment: LHCb\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: An anomaly detection based trigger for long lived particles decays in the LHCb muon detector\n",
      "Date: No date\n",
      "Abstract: {'summary': 'Long-lived particles are ubiquitous in many Standard Model extensions, and could provide solutions to long-standing problems in modern physics. In this work, machine-learning based techniques are developed and compared, in order to detect the presence of such particles in the LHCb muon detector. The models are designed to be implemented in the software triggers, making use of the GPU-accelerated hardware. In order to englobe a wide range of models, the techniques are chosen for their generality. Anomaly detection approaches, such as various types of autoencoders and Siamese neural networks, are benchmarked. Some preliminary implementations of a BDT and a $\\\\chi^2$ test are also presented. The performances of the models are very promising, and the models more easily adaptable to changing data-taking conditions.'}\n",
      "Experiment: LHCb\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Performance of new jet techniques based on machine learning for $H \\to b \\bar{b}$ and $H \\to c \\bar{c}$ searches \n",
      "Date: 2023-11-27\n",
      "Abstract: {'summary': 'n this document, the performance of two different machine learning techniques for jet physics at LHCb are presented: a new regression method for improving the jet energy correction, and a new jet identification method based on a Deep Neural Network for distinguish $b$, $c$ and light jets. These new algorithms will be used to perform the inclusive search for $H\\\\to b\\\\bar{b}$ and $H \\\\to c \\\\bar{c}$ decays. '}\n",
      "Experiment: No experiment\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Novel ML technique applications\n",
      "Date: 29 Sep 2024\n",
      "Abstract: {'summary': 'Machine learning (ML) is a rapidly growing area of research in the field of particle physics, with a vast array of applications at the CERN LHC. ML has changed the way particle physicists conduct searches and measurements as a versatile tool used to improve existing approaches and enable fundamentally new ones. In these proceedings, we describe novel ML techniques and recent results for improved classification, fast simulation, unfolding, and anomaly detection in LHC experiments.'}\n",
      "Experiment: ALICE,ATLAS,CMS,LHCB\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Event topology dependence of $J/\\psi$ production in proton+proton collisions at $\\sqrt{s} = 13$ TeV with ALICE at the LHC and Study of elliptic flow in heavy-ion collisions using event shape and machine learning techniques\n",
      "Date: No date\n",
      "Abstract: {'summary': 'Studies related to heavy-ion collisions at the most powerful particle accelerators in the world, the Large Hadron Collider (LHC) at CERN, Switzerland, and the Relativistic Heavy Ion Collider (RHIC) at BNL, USA, have primarily focused on the creation and properties of the primordial matter consisting quarks and gluons. This extremely dense and hot state of thermalized partons is also known as quark-gluon plasma (QGP). Due to the shorter lifetime of QGP, experiments rely on several indirect signatures that hint towards the formation of QGP in ultra-relativistic collisions of nuclear matter. While the formation of QGP has been established for a long time in heavy-ion collisions, its presence in small collision systems still needs to be determined. However, recent measurements of heavy-ion-like behavior in high-multiplicity pp collisions at the LHC have drawn the attention of the heavy-ion physics community. The appearance of ridge-like structures and the enhancement of strangeness add to these speculations. Increased production of strange hadrons can only be explained via forming a strongly interacting medium at thermal and chemical equilibrium. To determine whether the underlying physics processes involved in the strangeness production can also be probed with topological event selection instead of the average charged-particle multiplicity, a relatively new event shape classifier has been introduced at the LHC, known as the transverse spherocity ($S_0$). This event-shape observable can decouple the jet-dominated events from the events with spherical soft emission of particles. The first event is called the jetty type, and the latter is called the isotropic type. Jetty events result from enhanced contributions of perturbative QCD processes; however, isotropic events arise due to the interplay of several soft QCD processes, such as the multi-parton interactions and the initial and final state radiations. It is found that the production rates of strange particles are slightly higher for soft isotropic events and highly suppressed in hard jetty events. This supports the hypothesis that in high-multiplicity pp collisions, heavy-ion-like effects such as strangeness enhancement and radial flow are manifested in the isotropic events. Thus, transverse spherocity can separate events based on azimuthal topology and control heavy-ion-like effects in high-multiplicity pp collisions. A similar study of strange hadron production with topological event selection can also be performed for the case of charm hadrons. In the presence of QGP, the yield of charmonium ($c\\\\bar{c}$) is suppressed compared to the yield in the non-QGP scenarios in hadronic collisions. Therefore, studies involving charm hadrons with different topological event selections can help us understand its production mechanism and constrain various phenomenological models. Additionally, it can help us understand the observed heavy-ion-like effects in isotropic events in high-multiplicity pp collisions at the LHC. With these motivations, this analysis measures the $p_{\\\\rm T}$-differential yield of inclusive $J/\\\\psi$ as a function of transverse spherocity in high-multiplicity pp collisions at $\\\\sqrt{s} = 13$~TeV with ALICE. For this analysis, the reconstruction of $J/\\\\psi$ is performed through the electromagnetic decay channel, $J/\\\\psi \\\\rightarrow \\\\mu^{+}\\\\mu^{-}$ , B.R.~=~($5.961 \\\\pm 0.033)\\\\%$ in forward rapidity, $2.5<y<4.0$, using the forward muon spectrometer. For the estimation of transverse spherocity, midrapidity tracklets $(|\\\\eta|<0.8)$ are reconstructed using the Silicon Pixel Detector (SPD), which is the innermost central barrel detector in ALICE. The V0 scintillator detectors with a pseudorapidity coverage of $2.8<\\\\eta<5.1$ (V0A) and $-3.7<\\\\eta<-1.7$ (V0C) have been used for the estimation of event multiplicity. Such event shape-based analysis can also be implemented in heavy-ion collisions for different purposes. The appearance of strong transverse collectivity in non-central heavy-ion collisions is considered to be another signature of QGP. In non-central heavy-ion collisions, the initial spatial anisotropy gets converted into the final state momentum anisotropy during the medium evolution process and is reflected in the azimuthal momentum distribution of the charged particles. This is quantified as the anisotropic flow coefficients. To study the effect of topological event selection on the anisotropic flow coefficients, we implement transverse spherocity-based event shape analysis in heavy-ion collisions. Using transverse spherocity as an event shape tool, this study will complement the current event shape approach based on flow vectors in heavy-ion collisions. We report an extensive study of transverse spherocity dependence of elliptic flow of charged particles in Pb--Pb collisions at $\\\\sqrt{s_{\\\\rm NN}} = 5.02$~TeV using a multiphase transport model (AMPT). The elliptic flow for identified light-flavor hadrons and their number-of-constituent-quark scaling are also investigated in different event classes using transverse spherocity at RHIC and LHC energies. This study implements the two-particle correlation method to extract the transverse momentum differential elliptic flow coefficients. The two-particle correlation method helps in removing substantial nonflow from the calculation using a relative pseudorapidity cut between the particle pairs. Over the years, special attention has been given to the theoretical understanding of elliptic flow by modeling the medium evolution through relativistic hydrodynamics and various transport models. From the experimental side, the standard event plane method or the complex reaction plane identification method, the multi-particle correlation, and the cumulant method are usually followed to estimate elliptic flow. For the first time, we implement a feed-forward deep neural network to estimate the elliptic flow coefficient from the final state particle kinematics in heavy-ion collisions. The flow coefficients are embedded in the final state multi-particle correlations; hence, a deep neural network can be trained on simulated data to learn these correlations and efficiently measure the flow coefficients. The machine learning (ML) model is trained on simulated minimum bias Pb--Pb collisions at $\\\\sqrt{s_{\\\\rm NN}} = 5.02$~TeV using the AMPT string melting model. After successful training, the same ML model is applied across several collision systems at RHIC and LHC energies. Since elliptic flow has several dependencies, such as centrality, transverse momentum, particle species (or mass), and collision energy, it is interesting to explore the prediction capability of the ML model in these sectors. The model predictions for the elliptic flow of light-flavor hadrons and the number-of-constituent-quark scaling depicting the partonic level collectivity are also covered. These results from the ML model are compared to experimental findings, wherever possible.'}\n",
      "Experiment: ALICE\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Particle identification with machine learning from incomplete data in the ALICE experiment\n",
      "Date: 2024-03-26\n",
      "Abstract: [{'number': 'IOP', 'summary': 'The ALICE experiment at the LHC measures properties of the strongly interacting matterformed in ultrarelativistic heavy-ion collisions. Such studies require accurate particleidentification (PID). ALICE provides PID information via several detectors for particles withmomentum from about 100 MeV/c\\xa0up to 20 GeV/c. Traditionally, particles are selected withrectangular cuts. A\\xa0much better performance can be achieved with machine learning (ML)methods. Our solution uses multiple neural networks (NN) serving as binary classifiers. Moreover,we extended our particle classifier with Feature Set Embedding and attention in order to train ondata with incomplete samples. We also present the integration of the ML project with the ALICEanalysis software, and we discuss domain adaptation, the ML technique needed to transfer theknowledge between simulated and real experimental\\xa0data.'}, {'number': 'arXiv', 'summary': 'The ALICE experiment at the LHC measures properties of the strongly interacting matter formed in ultrarelativistic heavy-ion collisions. Such studies require accurate particle identification (PID). ALICE provides PID information via several detectors for particles with momentum from about 100 MeV/c up to 20 GeV/c. Traditionally, particles are selected with rectangular cuts. A much better performance can be achieved with machine learning (ML) methods. Our solution uses multiple neural networks (NN) serving as binary classifiers. Moreover, we extended our particle classifier with Feature Set Embedding and attention in order to train on data with incomplete samples. We also present the integration of the ML project with the ALICE analysis software, and we discuss domain adaptation, the ML technique needed to transfer the knowledge between simulated and real experimental data.'}]\n",
      "Experiment: ALICE\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Study of b-jet production and properties at the LHC\n",
      "Date: No date\n",
      "Abstract: {'summary': 'Jet production is a fundamental probe of perturbative quantum chromodynamics (pQCD).  They play a vital role also in other areas of high energy physics.  Jet quenching is arguably one of the most spectacular proofs of the creation of quark-gluon plasma in ultrarelativistic collisions of heavy ions. Nowadays, the rise of novel experimental techniques, including jet substructure observables and the application of machine learning algorithms,   are revolutionizing this field of study. New jet tagging capabilities allow for comparative studies between jet flavours.  Substructure measurements open doors for direct observation of the effects, entangled into more generic observables.  A perfect example is the dead-cone measurement by ALICE. Results shown in this thesis benefit from both of these advances. The first part describes the analysis of the beauty-jet production cross section,  measured in pp collisions at $\\\\sqrt{s}$ = 5.02 TeVby the ALICE experiment at the LHC.  It is the first application of machine learning for heavy-flavour jet measurements in ALICE. The new method significantly improves tagging efficiency and purity, and shows a good stability over a wide range of these parameters. Results are consistent with the NLO pQCD predictions and the ALICE results obtained with other methods. The second part shows simulation studies for the dead-cone effect  measurement for beauty jets in heavy-ion collisions. The study focuses on the removal of distortions introduced by uncorrelated heavy-ion background.  The combination of jet reclustering and jet grooming allows for the restoration of the quantitative properties related to the dead-cone effect of jets.  Additionally, this thesis highlights some potential issues that may arise during future measurements of this effect, which are not immediately apparent.'}\n",
      "Experiment: ALICE\n",
      "--------------------------------------------------\n",
      "\n",
      "Title: Non$-$prompt $\\mathrm{D}^0$ production in heavy$-$ion collisions with ALICE\n",
      "Date: No date\n",
      "Abstract: {'summary': 'The Quark$-$Gluon Plasma (QGP) is a new matter state composited by deconfined quarks and gluons which exist at extremely high temperature and energy density. This formation of matter, predicted by Quantum Chromodynamics (QCD) in the Standard Model, shows great importance as a phenomenon to test QCD theories with its phase transitions, where the properties of matter can be investigated in ultra$-$relativistic heavy$-$ion collision experiments. At the Large Hadron Collider (LHC), the produced experiments data of heavy ion collisions create possibility for QGP researches, with phenomena such as jet quenching, where high transverse momentum partons undergo energy loss interacting with de$-$confined medium via elastic processes or induced gluon radiations, and collective motions, where the expansion of bulk matter exhibits different patterns such as isotropic and anisotropic components which are physically driven by pressure gradients. Heavy quarks, are powerful probes of QGP due to their shorter formation timescale, and they are to mostly go through the full evolution of the collision system in space$-$time. $\\\\\\\\$  In this thesis, the measurements of non$-$prompt $\\\\mathrm{D}^{0}$ production in pp collisions at $\\\\sqrt{s}=5.02~\\\\mathrm{TeV}$ and in Pb$-$Pb collisions at $\\\\sqrt{{s_\\\\mathrm{NN}}}=5.02~\\\\mathrm{TeV}$ with ALICE detectors are reported. The measurements of non$-$prompt $\\\\mathrm{D}^{0}$, which are produced in beauty$-$hadron decays, can provide valuable information in beauty sector. The measurement of production in pp collisions is important to test perturbative QCD calculations, and provide a reference for Pb$-$Pb collisions. While in latter, the non$-$prompt $\\\\mathrm{D}^{0}$ measurement can help to study the microscopic beauty$-$medium interactions. At high $p_{\\\\mathrm{T}}$, it allows to investigate the colour charge and mass dependence of in$-$medium energy loss. At low $p_{\\\\mathrm{T}}$, the participation of system collective expansion and diffusion process for beauty quarks can be investigated. $\\\\\\\\$  In pp collisions, the $p_{\\\\mathrm{T}}$$-$differential production cross section of non$-$prompt $\\\\mathrm{D}^{0}$ is measured at midrapidity ($|y|<0.5$). The $\\\\mathrm{D}^{0}$ meson candidates are reconstructed via the hadronic decay channel $\\\\mathrm{D}^{0}\\\\rightarrow\\\\mathrm{K^{-}\\\\pi^{+}}$. Then specific selections based on Boosted Decision Trees (BDT), a machine learning model trained with pseudo$-$data from Monte Carlo simulations and background sample in data, are applied to the candidates. The application of BDT reduces the combinatorial background, and also to enhance the non--prompt fraction of $\\\\mathrm{D}^{0}$ from around 30$\\\\%$ to 90$\\\\%$ in signals. Afterwards, the signals are extracted via the invariant$-$mass analysis, and the non$-$prompt fractions are estimated with a data$-$driven minimizing$-$$\\\\chi^2$ approach. The measured $p_{\\\\mathrm{T}}$$-$differential cross section is within the transverse momentum range $1 \\\\lt p_{\\\\mathrm{T}} \\\\lt 24~\\\\mathrm{GeV}/c$. With an extrapolating method, the $p_{\\\\mathrm{T}}$$-$integrated cross section is estimated at high precision.  The results are well described by perturbative QCD (pQCD) calculations. The results are in good agreement with central prediction with FONLL calculated beauty hadron cross section and PYTHIA8 decay kinematics, while another prediction with GM$-$VFNS with two different transition approaches from beauty to non$-$prompt meson underestimated the measurement. Moreover, the total $\\\\mathrm{b\\\\bar{b}}$ production cross section is also determined from the measurements together with non$-$prompt $\\\\mathrm{D}^{0}$, $\\\\mathrm{D}^{+}$, and $\\\\mathrm{D^+_s}$ mesons, which is compatible with previous measurements of di--electron production at the same centre$-$of$-$mass energy as well as the cross section predicted by pQCD calculations such as FONLL and NNLO. The measured production in pp collisions also provide a reference for the same measurement in heavy$-$ion collisions. $\\\\\\\\$  While in Pb$-$Pb collisions, a similar measurement is performed at same per$-$nucleon$-$pair centre$-$of$-$mass energy. The nuclear modification factor ($R_{\\\\mathrm{AA}}$) of non$-$prompt $\\\\mathrm{D}^{0}$ was measured for the first time down to $p_{\\\\mathrm{T}}=1~\\\\mathrm{GeV}/c$ in $0-10\\\\%$ and $30-50\\\\%$ centrality classes. A suppression in $R_{\\\\mathrm{AA}}$ of factor about 3 (2) is observed for $p_\\\\mathrm{T}\\\\gt5~\\\\mathrm{GeV}/c$ in $0-10\\\\%$ ($30-50\\\\%$) centrality, while at lower $p_{\\\\mathrm{T}}$, $R_{\\\\mathrm{AA}}$ increases with decreasing $p_{\\\\mathrm{T}}$, and compatible with unity in $1 \\\\lt p_{\\\\mathrm{T}} \\\\lt 3~\\\\mathrm{GeV}/c$. The data are described by models that include both collisional and radiative processes in calculating beauty$-$quark energy loss in QGP, and quark recombination in addition to fragmentation as hadronization mechanism. The $R_{\\\\mathrm{AA}}$ ratios of non$-$prompt to prompt $\\\\mathrm{D}^{0}$$-$meson are reported significantly larger than unity at intermediate $p_{\\\\mathrm{T}}$ in $0-10\\\\%$ centrality, as predicted by transportation models in which the energy loss for beauty quarks are less than charm quarks due to their larger mass. $\\\\\\\\$'}\n",
      "Experiment: ALICE\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "if recent_results:\n",
    "    for record in recent_results:\n",
    "        # Print basic information if available\n",
    "        title = record.get('title', {}).get('title', 'No title')\n",
    "        abstract = record.get('abstract', 'No abstract')\n",
    "        date = record.get('prepublication', {}).get('date', 'No date')\n",
    "        # If accelerator_experiment is a list, take the first element\n",
    "        if isinstance(record.get('accelerator_experiment', {}), list):\n",
    "            experiment = record.get('accelerator_experiment', {})[0].get('experiment', 'No experiment')\n",
    "        else:\n",
    "            experiment = record.get('accelerator_experiment', {}).get('experiment', 'No experiment')\n",
    "        \n",
    "        print(f\"\\nTitle: {title}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Abstract: {abstract}\")\n",
    "        print(f\"Experiment: {experiment}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Searches for New Physics with top quarks using the ATLAS detector'}\n",
      "{'title': 'Recent Advances in the GAN-based Fast Calorimeter Simulation of the ATLAS Experiment'}\n",
      "{'title': 'Parameter Estimation in ATLAS with Neural Simulation-Based Inference'}\n",
      "{'title': 'Towards Machine-Learning Particle Flow with the ATLAS Detector at the LHC'}\n",
      "{'title': 'Improving Computational Performance of ATLAS GNN Track Reconstruction Pipeline'}\n",
      "{'title': 'ATLAS EFT Results in the Top Quark Sector'}\n",
      "{'title': 'The ATLAS inner detector trigger performance in Run 3'}\n",
      "{'title': 'An implementation of Neural Simulation-Based Inference for Parameter Estimation in ATLAS'}\n",
      "{'title': 'Treatment of systematic uncertainties in $b$-jet identification and measurement of Higgs boson decays to $b$-quarks with the ATLAS detector'}\n",
      "{'title': 'AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond'}\n",
      "{'title': 'Computational Performance of the ATLAS ITk GNN Track Reconstruction Pipeline'}\n",
      "{'title': 'Polarising Perspectives: Unveiling the Exotic in LHC Hadronic Jets'}\n",
      "{'title': 'Constraints on the Higgs self-coupling at the LHC with $\\\\sqrt{s}=13$ TeV and Long-Lived Particles searches with a future lepton collider'}\n",
      "{'title': 'Flavour Tagging with Graph Neural Network at ATLAS'}\n",
      "{'title': 'Higgs to charm at ATLAS from today to tomorrow'}\n",
      "{'title': 'The Fast Simulation Program of ATLAS at the LHC'}\n",
      "{'title': 'Novel ML technique applications'}\n",
      "{'title': 'Boosted Higgs decays to b-quarks in ATLAS'}\n",
      "{'title': 'Searches for new phenomena using Anomaly Detection at the ATLAS experiment'}\n",
      "{'title': 'The Beauty and Charm Yukawa Couplings of the Higgs Boson with the ATLAS Detector at the LHC. - 4D Tracking, Particle Flow and Jet Flavour Reconstruction Algorithms Development'}\n",
      "{'title': 'Performance versus uncertainty in boosted top tagging with the ATLAS detector'}\n",
      "{'title': 'Flavour Tagging with Graph Neural Network with the ATLAS Detector'}\n",
      "{'title': 'Boosted Decision Trees for the ATLAS Level-1 Calorimeter Tau Trigger'}\n",
      "{'title': 'ATLAS searches for electroweak supersymmetry with compressed spectra'}\n",
      "{'title': 'Measurement of Higgs Boson Decays to Bottom and Charm Quarks in the $WH$ Production Channel with the ATLAS Experiment'}\n",
      "{'title': 'Semi-Supervised Learning for Semi-Visible Jets: A Search for Dark Matter Jets at the LHC with the ATLAS Detector'}\n",
      "{'title': 'Boosting CPU Efficiency in ATLAS Inner Detector Reconstruction with Track Overlay'}\n",
      "{'title': 'Flavour Tagging with Graph Neural Network at ATLAS'}\n",
      "{'title': 'Classifying hadronic objects in ATLAS with ML/AI algorithms'}\n",
      "{'title': 'Searches for new physics using unsupervised machine learning for anomaly detection in $\\\\sqrt{s}$ = 13 TeV $pp$ collisions recorded by the ATLAS detector at the LHC'}\n",
      "{'title': 'Classifying hadronic objects in ATLAS with ML/AI algorithms'}\n",
      "{'title': 'New ATLAS $t\\\\bar{t}H(b\\\\bar{b})$ Run 2 Analysis'}\n",
      "{'title': 'Measurement of Track Functions in ATLAS Run 2 Data'}\n",
      "{'title': 'Accuracy versus precision in boosted top tagging with the ATLAS detector'}\n",
      "{'title': 'Deployment of ATLAS Calorimeter Fast Simulation Training Through Container Technology'}\n",
      "{'title': 'A Function-as-a-Task Workflow Management Approach with PanDA and iDDS'}\n",
      "{'title': 'The Fast Simulation Program of ATLAS at the LHC'}\n",
      "{'title': 'Enhancing Prompt Lepton Identification: Development and Optimization of the PLIT Tagger'}\n",
      "{'title': 'Searches for new phenomena using Anomaly Detection at the ATLAS experiment'}\n",
      "{'title': 'A novel approach for real-time identification of hadronic final states at the High-Luminosity LHC.'}\n",
      "{'title': 'Generative Models for High Energy Physics Measurements'}\n",
      "{'title': 'Recent results on SUSY searches in ATLAS'}\n",
      "{'title': 'Enhancing Prompt Lepton Identification: Development and Optimization of the PLIT Tagger'}\n",
      "{'title': 'A simultaneous unbinned differential cross section measurement of twenty-four $Z$+jets kinematic observables with the ATLAS detector'}\n",
      "{'title': 'Real particle physics analysis by UK secondary school students using the ATLAS Open Data: An illustration through a collection of original student research'}\n",
      "{'title': 'Extending the Reach of Searches for Staus, Charginos and Neutralinos with the ATLAS Experiment at the Large Hadron Collider '}\n",
      "{'title': 'Search for intrinsic charm in the proton at the ATLAS experiment'}\n",
      "{'title': 'Search for the Higgs boson produced in association with a  top quark using $\\\\tau$ leptons with ATLAS'}\n",
      "{'title': 'Deployment of ATLAS Calorimeter Fast Simulation Training Through Container Technology'}\n",
      "{'title': 'AtlFast3: Fast Simulation in ATLAS for LHC Run 3 and beyond'}\n",
      "{'title': 'Boosting CPU Efficiency in ATLAS Inner Detector Reconstruction with Track Overlay'}\n",
      "{'title': 'A Function-as-a-Task Workflow Management Approach with PanDA and iDDS'}\n",
      "{'title': 'Search for Higgs boson decays to two charm quarks at ATLAS'}\n",
      "{'title': 'Flavor tagging performance in ATLAS and CMS with an emphasis on HH and multi-Higgs searches'}\n",
      "{'title': 'Exploring the Limits of the Standard Model with the ATLAS Experiment at the LHC'}\n",
      "{'title': 'Machine learning in high energy physics at LHC'}\n",
      "{'title': 'Track reconstruction for the ATLAS Phase-II High-Level Trigger using Graph Neural Networks on FPGAs'}\n",
      "{'title': 'Automation of the b-tagging calibration software in ATLAS'}\n",
      "{'title': 'Anomaly detection in CMS'}\n",
      "{'title': 'Run 3 commissioning results of heavy-flavor jet tagging at $\\\\sqrt{s}=$ 13.6 TeV with CMS data using a modern framework for data processing'}\n",
      "{'title': 'Anomaly detection in CMS'}\n",
      "{'title': 'Search for charged lepton flavor violation in top quark interaction with an up-type quark, a muon, and a $\\\\tau$ lepton with the CMS experiment'}\n",
      "{'title': 'Performance of the CMS high-level trigger during LHC Run 2'}\n",
      "{'title': 'FlashSim'}\n",
      "{'title': 'Machine learning based tau lepton identification for the CMS high-level trigger deployed for 13.6 TeV proton-proton collisions'}\n",
      "{'title': 'Novel ML technique applications'}\n",
      "{'title': 'Identification of Lorentz-boosted jets in the CMS experiment'}\n",
      "{'title': 'Identification of Lorentz-boosted jets in the CMS experiment'}\n",
      "{'title': 'Measurement of event shape variables in pp collisions'}\n",
      "{'title': 'Tau lepton identification in displaced topologies using machine learning at CMS'}\n",
      "{'title': 'Identification of Lorentz-boosted jets in the CMS experiment'}\n",
      "{'title': 'Measurement of event shape variables in pp collisions'}\n",
      "{'title': 'Ricerche di nuova fisica con oggetti pesanti ad alto boost di Lorentz in eventi con jet'}\n",
      "{'title': 'Search for light long-lived particles decaying to displaced jets in proton-proton collisions at $ \\\\sqrt{s} = $ 13.6 TeV'}\n",
      "{'title': 'New directions for particle tracking at the High-Luminosity LHC'}\n",
      "{'title': 'Boosted jet identification at the CMS experiment'}\n",
      "{'title': 'Low Energy Leptons in High Energy Physics: A Search for Physics beyond the Standard Model with Compressed Mass-Spectra and New Algorithms for Triggering on Electrons at the High Luminosity LHC'}\n",
      "{'title': 'Search for lepton flavour violation in top quark interactions with an up-type quark, a muon, and a tau lepton'}\n",
      "{'title': 'Search for Higgs Boson Production in Association with b-Quarks in Final States with Leptons with Machine Learning Techniques at CMS'}\n",
      "{'title': 'CMS tracker data quality certification with new machine learning tools'}\n",
      "{'title': 'Run 3 detector paper L1T Plots'}\n",
      "{'title': 'Reweighting of simulated events using machine learning techniques in CMS'}\n",
      "{'title': 'Jet energy scale and resolution of jets with ParticleNet $p_{\\\\mathrm{T}}$ regression using Run3 data collected by the CMS experiment in 2022 and 2023 at 13.6 TeV'}\n",
      "{'title': 'A unified approach for jet tagging in Run 3 at $\\\\sqrt{s}$=13.6 TeV in CMS'}\n",
      "{'title': 'Jet energy scale and resolution of jets with ParticleNet $p_{\\\\mathrm{T}}$ regression using Run3 data collected by the CMS experiment in 2022 and 2023 at 13.6 TeV'}\n",
      "{'title': 'Performance of the CNN-based tau identification algorithm with Domain Adaptation using Adversarial Machine Learning for Run 3'}\n",
      "{'title': 'Tau lepton identification in displaced topologies using machine learning at CMS'}\n",
      "{'title': 'Measurement of boosted Higgs bosons produced via vector boson fusion or gluon fusion in the $ \\\\mathrm{H}\\\\to\\\\mathrm{b}\\\\overline{\\\\mathrm{b}} $ decay mode using LHC proton-proton collision data at $ \\\\sqrt{s} = $ 13 TeV'}\n",
      "{'title': 'Search for top squarks in final states with many light flavor jets and 0, 1, or 2 leptons in proton-proton collisions at sqrt(s) = 13 TeV'}\n",
      "{'title': 'Run 3 commissioning results of heavy-flavor jet tagging at $\\\\sqrt{s}=$13.6 TeV with CMS data using a modern framework for data processing'}\n",
      "{'title': 'Emerging Jets Search, Triton Server Deployment, and Track Quality Development: Machine Learning Applications in High Energy Physics'}\n",
      "{'title': 'Searches for New Physics in Top-Antitop Associated Production Processes and Mechanical Design and Thermal Performance of the CMS Inner Tracker Endcap Pixel Upgrade'}\n",
      "{'title': 'NNPuppiTaus: PUPPI tau reconstruction in the Level-1 trigger with real-time machine learning'}\n",
      "{'title': 'Measurement of time-dependent $CP$ violation in $B_s^0 \\\\to J/\\\\psi\\\\, \\\\phi(1020)$ decays with the CMS detector'}\n",
      "{'title': 'Development of calibration techniques and performance analysis of the CMS Inner Tracker for the High Luminosity phase of LHC'}\n",
      "{'title': 'Search for low-mass long-lived particles decaying to displaced jets in proton-proton collisions at $\\\\sqrt{s} = 13.6~\\\\mathrm{TeV}$'}\n",
      "{'title': 'Model-agnostic search for dijet resonances with anomalous jet substructure in proton-proton collisions at $\\\\sqrt{s}$ = 13 TeV'}\n",
      "{'title': 'Searches for New Physics in Top-Antitop Associated Production Processes and Mechanical Design and Thermal Performance of the CMS Inner Tracker Endcap Pixel Upgrade'}\n",
      "{'title': 'Search for long-lived particles using displaced vertices and missing transverse momentum in proton-proton collisions at $ \\\\sqrt{s}= $ 13 TeV'}\n",
      "{'title': 'Portable Acceleration of CMS Computing Workflows with Coprocessors as a Service'}\n",
      "{'title': 'Accelerating Full and Fast Simulation of the CMS Experiment'}\n",
      "{'title': 'A Search for Long-Lived Particles in Signatures With Displaced Vertex Using Novel Machine Learning Techniques at CMS'}\n",
      "{'title': 'Kalman filter for muon reconstruction in the CMS Phase-2 endcap calorimeter'}\n",
      "{'title': 'DeepCore 2.0: Convolutional Neural Network for Tracking in Jets with High Transverse Momentum'}\n",
      "{'title': 'Study of the production processes of top quarks and missing energy predicted by the Standard Model and its extensions, in leptonic final states with the CMS detector at the LHC using machine learning techniques.'}\n",
      "{'title': 'CMS Level-1 Trigger Upgrade'}\n",
      "{'title': 'Measurement of the differential dileptonic t$\\\\bar{\\\\text{t}}$ cross section in a BSM phase space with the CMS detector using the full LHC Run 2 data set'}\n",
      "{'title': 'Prompt signature searches in CMS'}\n",
      "{'title': 'CMS highlights on searches for new physics in final states with jets'}\n",
      "{'title': 'CMS measurements of top quark pair/single top + boson production (incl. EFT searches)'}\n",
      "{'title': 'Probing Quark Hadronization with B mesons at the LHC'}\n",
      "{'title': 'Measurements on the production of a Z boson in association with a photon in proton-proton collisions and a search for anomalous triple gauge couplings at the CERN Large Hadron Collider'}\n",
      "{'title': 'Measurements on the production of a Z boson in association with a photon in proton-proton collisions and a search for anomalous triple gauge couplings at the CERN Large Hadron Collider'}\n",
      "{'title': 'Improving tracking algorithms with machine learning  a case for line-segment tracking at the High Luminosity LHC'}\n",
      "{'title': 'Development of machine learning based $\\\\tau$ trigger algorithms and search for Higgs boson pair production in the bb$\\\\tau$$\\\\tau$ decay channel with the CMS detector at the LHC'}\n",
      "{'title': 'Machine learning techniques for model-independent searches in dijet final states'}\n",
      "{'title': 'Level-1 Trigger Calorimeter Image Convolutional Anomaly Detection Algorithm'}\n",
      "{'title': 'Supersymmetry searches with heavy object tagging and tau leptons in CMS'}\n",
      "{'title': 'Development and firmware implementation of a Machine Learning based hadronic Tau lepton Level-1 Trigger algorithm in CMS for the HL-LHC'}\n",
      "{'title': 'Overview of the HL-LHC Upgrade for the CMS Level-1 Trigger'}\n",
      "{'title': 'Design and implementation of Neural Network based conditions for the CMS Level-1 Global Trigger upgrade for the HL-LHC'}\n",
      "{'title': 'The flash-simulation paradigm and its implementation based on Deep Generative Models for the LHCb experiment at CERN'}\n",
      "{'title': 'An anomaly detection based trigger for long lived particles decays in the LHCb muon detector'}\n",
      "{'title': 'Performance of new jet techniques based on machine learning for $H \\\\to b \\\\bar{b}$ and $H \\\\to c \\\\bar{c}$ searches '}\n",
      "{'title': 'Novel ML technique applications'}\n",
      "{'title': 'Event topology dependence of $J/\\\\psi$ production in proton+proton collisions at $\\\\sqrt{s} = 13$ TeV with ALICE at the LHC and Study of elliptic flow in heavy-ion collisions using event shape and machine learning techniques'}\n",
      "{'title': 'Particle identification with machine learning from incomplete data in the ALICE experiment'}\n",
      "{'title': 'Study of b-jet production and properties at the LHC'}\n",
      "{'title': 'Non$-$prompt $\\\\mathrm{D}^0$ production in heavy$-$ion collisions with ALICE'}\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "\n",
    "for record in recent_results:\n",
    "    print(record[\"title\"])\n",
    "    try:\n",
    "        record[\"title\"] = record[\"title\"][\"title\"]\n",
    "        # Handle case where abstract is a list\n",
    "        if isinstance(record[\"abstract\"], list):\n",
    "            record[\"abstract\"] = record[\"abstract\"][0]\n",
    "        record[\"abstract\"] = record[\"abstract\"][\"summary\"]\n",
    "        # If accelerator_experiment is a list, take the first element\n",
    "        if isinstance(record.get('accelerator_experiment', {}), list):\n",
    "            record[\"experiment\"] = record.get('accelerator_experiment', {})[0].get('experiment', 'No experiment')\n",
    "        else:\n",
    "            record[\"experiment\"] = record.get('accelerator_experiment', {}).get('experiment', 'No experiment')\n",
    "    except:\n",
    "        print(f\"No abstract for {record['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lhc_combined_data.json', 'w') as f:\n",
    "    json.dump(recent_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hamlet_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
